#include<iostream>
using namespace std;
#include <cstdint>
#include <cstdlib>
#include <cstdio>
#include <cmath>
#include <vector>

#define FETCH_FLOAT4(pointer) (reinterpret_cast<float4*>(&(pointer))[0])

__device__ __forceinline__
uint32_t smem_u32addr(const void *smem_ptr) {
	uint32_t addr;
	asm("{.reg .u64 u64addr;\n"
		" cvta.to.shared.u64 u64addr, %1;\n"
		" cvt.u32.u64 %0, u64addr;}\n"
		: "=r"(addr)
		: "l"(smem_ptr)
	);

	return addr;
}

__device__ __forceinline__
void ldg32_nc(float &reg, const void *ptr, bool guard) {
	asm volatile (
		"{.reg .pred p;\n"
		" setp.ne.b32 p, %2, 0;\n"
#if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 && \
    __CUDA_ARCH__ >= 750
		" @p ld.global.nc.L2::128B.f32 %0, [%1];}\n"
#else
		" @p ld.global.nc.f32 %0, [%1];}\n"
#endif
		: "=f"(reg)
		: "l"(ptr), "r"((int)guard)
		);
}

// __device__ __forceinline__
// void ldg32_nc_0(float &reg, const void *ptr, bool guard) {
//     asm volatile (
//         "{.reg .pred p;\n"
//         " setp.ne.b32 p, %2, 0;\n"
//         " @!p mov.b32 %0, 0;\n"
// #if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 && \
//     __CUDA_ARCH__ >= 750
//         " @p ld.global.nc.L2::128B.f32 %0, [%1];}\n"
// #else
//         " @p ld.global.nc.f32 %0, [%1];}\n"
// #endif
//         : "=f"(reg)
//         : "l"(ptr), "r"((int)guard)
//     );
// }  6.25KB。


__device__ __forceinline__ void ldg32_nc_0(float &reg, const void *ptr) {
	asm volatile("{mov.b32 %0, 0;\n"
#if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 &&                 \
    __CUDA_ARCH__ >= 750
		"ld.global.nc.L2::128B.f32 %0, [%1];}\n"
#else
		"ld.global.nc.f32 %0, [%1];}\n"
#endif
		: "=f"(reg)
		: "l"(ptr));
}


__device__ __forceinline__
void stg32(const float &reg, void *ptr, bool guard) {
	asm volatile (
		"{.reg .pred p;\n"
		" setp.ne.b32 p, %2, 0;\n"
		" @p st.global.f32 [%0], %1;}\n"
		: : "l"(ptr), "f"(reg), "r"((int)guard)
		);
}

__device__ __forceinline__
void lds128(float &reg0, float &reg1,
	float &reg2, float &reg3,
	const uint32_t &addr) {
	asm volatile (
		"ld.shared.v4.f32 {%0, %1, %2, %3}, [%4];\n"
		: "=f"(reg0), "=f"(reg1), "=f"(reg2), "=f"(reg3)
		: "r"(addr)
		);
}

__device__ __forceinline__
void sts32(const float &reg, const uint32_t &addr) {
	asm volatile (
		"st.shared.f32 [%0], %1;\n"
		: : "r"(addr), "f"(reg)
		);
}

__device__ __forceinline__
void sts128(const float &reg0, const float &reg1,
	const float &reg2, const float &reg3,
	const uint32_t &addr) {
	asm volatile (
		"st.shared.v4.f32 [%0], {%1, %2, %3, %4};\n"
		: : "r"(addr), "f"(reg0), "f"(reg1), "f"(reg2), "f"(reg3)
		);
}

struct StgFrag {
	float data[4][4];

	__device__ __forceinline__
		StgFrag(const float(&C_frag)[8][8], int tile_x, int tile_y) {
#pragma unroll
		for (int i = 0; i < 4; ++i) {
#pragma unroll
			for (int j = 0; j < 4; ++j) {
				data[i][j] = C_frag[tile_y * 4 + i][tile_x * 4 + j];
			}
		}
	}
};

__device__ __noinline__
void C_tile_wb(StgFrag C_frag,
	float *C_stg_ptr,
	const float *C_lds_ptr,
	uint32_t C_sts_addr,
	uint32_t m,
	uint32_t n,
	uint32_t m_idx,
	uint32_t n_idx) {
	__syncthreads();

#pragma unroll
	for (int i = 0; i < 4; ++i) {
		sts128(C_frag.data[i][0],
			C_frag.data[i][1],
			C_frag.data[i][2],
			C_frag.data[i][3],
			C_sts_addr + i * 8 * sizeof(float4));
	}

	__syncthreads();

	uint32_t m_guard = m < m_idx ? 0 : m - m_idx;

#pragma unroll
	for (int i = 0; i < 16; ++i) {
		stg32(C_lds_ptr[i * 32],
			C_stg_ptr + i * n,
			i < m_guard && n_idx < n);
	}
}

__device__ __forceinline__ void stg128(const float &reg0, const float &reg1,
	const float &reg2, const float &reg3,
	const float *addr) {
	asm volatile("st.global.v4.f32 [%0], {%1, %2, %3, %4};\n"
		:
	: "l"(addr), "f"(reg0), "f"(reg1), "f"(reg2), "f"(reg3));
}

/*
 * matrix A, B and C: row-major
 *
 * mma block:
 * thread block tile: m128n128k8
 * warp tile: m32n64k8
 * thread tile: m8n8k8
 * thread fragment:
 *     matrixA: 8x1 FP32
 *     matrixB: 1x8 FP32
 *
 * ----------------------------------------------------------------
 * thread block tile map:
 *
 *                                128
 *                    --|---------------------|
 *             B_tile  8|                     |
 *                    --|---------------------|
 *
 *  A_tile   | 8 |      |    64    |
 *         --|---|    --|----------|----------|
 *           |   |    32|  warp_0  |  warp_1  |
 *           |   |    --|----------|----------|
 *           |   |      |  warp_2  |  warp_3  |
 *        128|   |      |----------|----------|
 *           |   |      |  warp_4  |  warp_5  |
 *           |   |      |----------|----------|
 *           |   |      |  warp_6  |  warp_7  |
 *         --|---|      |----------|----------|
 *
 * ----------------------------------------------------------------
 * warp tile map:
 *
 * 'z' thread map to avoid LDS.128 shared memory broadcast limitation.
 *
 *              |              32               ||
 *     B_frag --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
 *             1|///|   |   |   |   |   |   |   ||///|   |   |   |   |   |   |   |
 *            --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
 * A_frag       | 4 |                           ||
 *    | 1 |                                     ||
 *  --|---|--   |---|---|---|---|---|---|---|---||---|---------------------------|
 *    |///|4    |t0 |t2 |t4 |t6 |t8 |t10|t12|t14||t0 |                           |
 *    |---|--   |---|---|---|---|---|---|---|---||---|                           |
 *    |   |     |t1 |t3 |t5 |t7 |t9 |t11|t13|t15||                               |
 *  16|---|     |---|---|---|---|---|---|---|---||                               |
 *    |   |     |t16|t18|t20|t22|t24|t26|t28|t30||                               |
 *    |---|     |---|---|---|---|---|---|---|---||                               |
 *    |   |     |t17|t19|t21|t23|t25|t27|t29|t31||                               |
 *  ==|===|=====|===|===|===|===|===|===|===|===||===|============================
 *    |///|     |t0 |                           ||t0 |                           |
 *    |---|     |---|                           ||---|                           |
 *    |   |     |                               ||                               |
 *    |---|     |                               ||                               |
 *    |   |     |                               ||                               |
 *    |---|     |                               ||                               |
 *    |   |     |                               ||                               |
 *    |---|     |-------------------------------||-------------------------------|
 *
 */
__global__ void sgemm_128x128x8(uint32_t m,
	uint32_t n,
	uint32_t k,
	float *A,
	float *B,
	float *C) {
	/*
	 * matrix A & B thread block tile shared memory (double buffer)
	 * matrix A: 132 * 8 * 4Byte/item * double buffer = 4.125KB * 2
	 * matrix B: 128 * 8 * 4Byte/item * double buffer = 8KB
	 *
	 * for double buffer faster switch, A_smem requires 8KB * 2 shared memory
	 * and 16KB aligned, B_smem should be 8KB aligned, then the double buffer
	 * can be switched by only 1 xor instruction:
	 *     (uint32_t &)A_smem ^= 0x2000;
	 *     (uint32_t &)B_smem ^= 0x1000;
	 */
	__shared__ __align__(2 * 1024) char smem[6400];
	float *A_smem = reinterpret_cast<float *>(smem);
	float *B_smem = reinterpret_cast<float *>(smem + 2304);

	// A, B and C register fragment
	float A_frag[2][8];
	float B_frag[2][8];
	float C_frag[8][8];
#pragma unroll
	for (int i = 0; i < 8; ++i) {
#pragma unroll
		for (int j = 0; j < 8; ++j) {
			C_frag[i][j] = 0;
		}
	}

	const uint32_t lane_id = threadIdx.x % 32;
	const uint32_t warp_id = threadIdx.x / 32;

	// 4x8 threads each warp for FFMA
	const uint32_t mma_tid_x = (lane_id / 2) % 8;
	const uint32_t mma_tid_y = (lane_id / 16) * 2 + (lane_id % 2);

	// A_tile & B_tile ldg pointer
	int from_a = (blockIdx.y * 32 + (threadIdx.x % 32) / 4 * 4) * k + (threadIdx.x % 32) % 4 + (threadIdx.x / 32)*(k / 2);
	int from_b = ((threadIdx.x % 32) / 16 + (threadIdx.x / 32)*(k / 2)) * n + blockIdx.x * 64 + (threadIdx.x % 32) % 16 * 4;

	// A_tile & B_tile sts/lds pointer
	// using uint32_t pointer for faster double buffer switch

	uint32_t A_lds_addr = smem_u32addr(
		A_smem + mma_tid_y * 4 + (threadIdx.x / 32) * 36 * 4);
	uint32_t B_lds_addr = smem_u32addr(
		B_smem + mma_tid_x * 4 + (threadIdx.x / 32) * 64 * 4);  // 读取共享内存，存到寄存器去


	float4 b_ldg_reg[2];
	float a_ldg_reg[4];

	uint32_t a_sts_addr = smem_u32addr(A_smem + ((threadIdx.x % 32) % 4) * 36 + ((threadIdx.x % 32) / 4) * 4 + (threadIdx.x / 32) * 36 * 4);
	uint32_t b_sts_addr = smem_u32addr(B_smem + ((threadIdx.x % 32) / 16) * 64 + ((threadIdx.x % 32) % 16) * 4 + (threadIdx.x / 32) * 64 * 4);

	// 1'st A&B tile loaded before the k_tile loop
	uint32_t k_tiles = (k / 2 + 3) / 4 - 1;
	uint32_t first_k_tile = k / 2 - k_tiles * 4 + (k / 2)*(threadIdx.x / 32);

	// load 1'st tile to shared memory
	{
		// load first
		// load gmem to smem for ashare
// 		if(threadIdx.x==0&&blockIdx.x==0){
// 		    printf("first_k_tile=%d\n", first_k_tile);
// 		}
#pragma unroll
		for (int i = 0; i < 4; ++i) {
			if ((threadIdx.x % 32) % 4 + (threadIdx.x / 32)*(k / 2) < first_k_tile  && blockIdx.y * 32 + (threadIdx.x % 32) / 4 * 4 + i < m) {
				ldg32_nc_0(a_ldg_reg[i], (const char *)(A + from_a) + i * k * sizeof(float));
			}
			else {
				a_ldg_reg[i] = 0;
			}
		}

		// 		printf("%f %f %f %f th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
		sts128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], a_sts_addr);



		// load gmem to smem for bshare
// 		if(threadIdx.x==32){
// 		    printf("a1=%f < a2=%f, a3=%f<a4=%f\n", from_b , (1+(threadIdx.x % 32)/16 + (threadIdx.x / 32)*(k / 2))*n)
// 		}
		if (from_b < (1 + (threadIdx.x % 32) / 16 + (threadIdx.x / 32)*(k / 2))*n) {
			if ((threadIdx.x % 32) / 16 + (threadIdx.x / 32)*(k / 2) + 2 < first_k_tile) {

				b_ldg_reg[0] = FETCH_FLOAT4(B[from_b]);
				b_ldg_reg[1] = FETCH_FLOAT4(B[from_b + 2 * n]);

			}
			else if ((threadIdx.x % 32) / 16 < first_k_tile) {
				b_ldg_reg[0] = FETCH_FLOAT4(B[from_b]);
				b_ldg_reg[1] = float4{ 0, 0, 0, 0 };
				// 	            if(threadIdx.x==32){
				// 	                printf("32_read=%f %f %f %f,%f %f %f %f\n", b_ldg_reg[0].x, b_ldg_reg[0].y, b_ldg_reg[0].z, b_ldg_reg[0].w,b_ldg_reg[1].x, b_ldg_reg[1].y, b_ldg_reg[1].z, b_ldg_reg[1].w);
				// 	            }
			}
			else {
				b_ldg_reg[0] = float4{ 0, 0, 0, 0 };
				b_ldg_reg[1] = float4{ 0, 0, 0, 0 };
			}
		}
		else {
			b_ldg_reg[0] = float4{ 0, 0, 0, 0 };
			b_ldg_reg[1] = float4{ 0, 0, 0, 0 };
		}


		FETCH_FLOAT4(B_smem[((threadIdx.x % 32) / 16) * 64 + ((threadIdx.x % 32) % 16) * 4 + (threadIdx.x / 32) * 64 * 4]) = b_ldg_reg[0];
		FETCH_FLOAT4(B_smem[((threadIdx.x % 32) / 16) * 64 + ((threadIdx.x % 32) % 16) * 4 + (threadIdx.x / 32) * 64 * 4 + 64 * 2]) = b_ldg_reg[1];
		__syncthreads();

		// add offset and flip flag
		from_a += k / 2 - k_tiles * 4;
		from_b += (k / 2 - k_tiles * 4) * n;
		a_sts_addr += 36 * 4 * 2 * sizeof(float);  // 此处的*2是因为slice2！！！
		b_sts_addr += 64 * 4 * 2 * sizeof(float);
	}

	//     if(threadIdx.x==0 && blockIdx.x==0){
	//         for(int ii=0;ii<8;ii++){
	//             for(int jj=0;jj<32;jj++){
	//                 if(A_smem[ii*36+jj]!=0){
	//                     printf("A_smem[%d][%d]=%f  ", ii, jj, A_smem[ii*36+jj]);
	//                 }
	//             }
	//             printf("\n");
	//         }
	//         printf("\n");
	//
	//         for(int ii=0;ii<8;ii++){
	//             for(int jj=0;jj<64;jj++){
	//                 if(B_smem[ii*64+jj]!=0){
	//                     printf("B_smem[%d][%d]=%f  ", ii, jj, B_smem[ii*64+jj]);
	//                 }
	//             }
	//             printf("\n");
	//         }
	//         printf("\n");
	//     }

		// load 1'st fragment
	lds128(A_frag[0][0], A_frag[0][1], A_frag[0][2], A_frag[0][3],
		A_lds_addr);
	lds128(A_frag[0][4], A_frag[0][5], A_frag[0][6], A_frag[0][7],
		A_lds_addr + 16 * sizeof(float));
	lds128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3],
		B_lds_addr);
	lds128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7],
		B_lds_addr + 32 * sizeof(float));
	int jump = 0;
	// k_tiles loop
	for (; k_tiles > 0; --k_tiles) {
		//         if(threadIdx.x==0 && blockIdx.x==0){
		//             printf("k_tiles=%d\n", k_tiles);
		//         }
		jump ^= 1;
#pragma unroll
		for (int k_frag = 0; k_frag < 4; ++k_frag) {
			// store next A&B tile to shared memory
			if (k_frag == 3) {
				sts128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3],
					a_sts_addr);
				//
				sts128(b_ldg_reg[0].x, b_ldg_reg[0].y, b_ldg_reg[0].z, b_ldg_reg[0].w, b_sts_addr);
				sts128(b_ldg_reg[1].x, b_ldg_reg[1].y, b_ldg_reg[1].z, b_ldg_reg[1].w, b_sts_addr + sizeof(float) * 2 * 64);
				__syncthreads();

				//                 if(threadIdx.x==0 && blockIdx.x==0){
				//                     for(int ii=0;ii<4;ii++){
				//                         for(int jj=0;jj<32;jj++){
				//                             if(A_smem[ii*36+jj+36*4*2*jump]!=0){
				//                                 printf("11A_smem[%d][%d]=%f  ", ii, jj, A_smem[ii*36+jj+36*4*2*jump]);
				//                             }
				//                         }
				//                         printf("\n");
				//                     }
				//                     printf("\n");
				//
				//
				//                     for(int ii=0;ii<4;ii++){
				//                         for(int jj=0;jj<64;jj++){
				//                             if(B_smem[ii*64+jj+64*4*2*jump]!=0){
				//                                 printf("11B_smem[%d][%d]=%f  ", ii, jj, B_smem[ii*64+jj+64*4*2*jump]);
				//                             }
				//                         }
				//                         printf("\n");
				//                     }
				//                     printf("\n");
				//                 }
								// switch double buffer
				if (jump == 1) {
					A_lds_addr += 36 * 4 * 2 * sizeof(float);
					B_lds_addr += 64 * 4 * 2 * sizeof(float);
					a_sts_addr -= 36 * 4 * 2 * sizeof(float);
					b_sts_addr -= 64 * 4 * 2 * sizeof(float);
				}
				else {
					A_lds_addr -= 36 * 4 * 2 * sizeof(float);
					B_lds_addr -= 64 * 4 * 2 * sizeof(float);
					a_sts_addr += 36 * 4 * 2 * sizeof(float);
					b_sts_addr += 64 * 4 * 2 * sizeof(float);
				}


				// ldg pointer for next tile
				from_a += 4;
				from_b += 4 * n;
			}

			// load next A&B fragment from shared memory to register
			lds128(A_frag[(k_frag + 1) % 2][0],
				A_frag[(k_frag + 1) % 2][1],
				A_frag[(k_frag + 1) % 2][2],
				A_frag[(k_frag + 1) % 2][3],
				A_lds_addr + (k_frag + 1) % 4 * 36 * sizeof(float));
			lds128(A_frag[(k_frag + 1) % 2][4],
				A_frag[(k_frag + 1) % 2][5],
				A_frag[(k_frag + 1) % 2][6],
				A_frag[(k_frag + 1) % 2][7],
				A_lds_addr + ((k_frag + 1) % 4 * 36 + 16) * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][0],
				B_frag[(k_frag + 1) % 2][1],
				B_frag[(k_frag + 1) % 2][2],
				B_frag[(k_frag + 1) % 2][3],
				B_lds_addr + (k_frag + 1) % 4 * 64 * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][4],
				B_frag[(k_frag + 1) % 2][5],
				B_frag[(k_frag + 1) % 2][6],
				B_frag[(k_frag + 1) % 2][7],
				B_lds_addr + ((k_frag + 1) % 4 * 64 + 32) * sizeof(float));

			// load next A&B tile
			if (k_frag == 0) {


				if (from_b < (1 + (threadIdx.x % 32) / 16)*n + (-k_tiles * 4 + k / 2 + (threadIdx.x / 32)*(k / 2))*n) {
					if ((-k_tiles * 4 + k / 2) + (threadIdx.x % 32) / 16 + (threadIdx.x / 32)*(k / 2) + 2 < k) {

						b_ldg_reg[0] = FETCH_FLOAT4(B[from_b]);
						b_ldg_reg[1] = FETCH_FLOAT4(B[from_b + 2 * n]);
						//                         if(threadIdx.x==0){
						//                             printf("value=%f %f %f %f\n",b_ldg_reg[0].x,b_ldg_reg[0].y, b_ldg_reg[0].z, b_ldg_reg[0].w);
						//                         }
					}
					else if ((-k_tiles * 4 + k / 2) + (threadIdx.x % 32) / 16 + (threadIdx.x / 32)*(k / 2) < k) {
						b_ldg_reg[0] = FETCH_FLOAT4(B[from_b]);
						b_ldg_reg[1] = float4{ 0, 0, 0, 0 };
					}
					else {
						b_ldg_reg[0] = float4{ 0, 0, 0, 0 };
						b_ldg_reg[1] = float4{ 0, 0, 0, 0 };
					}
				}
				else {
					b_ldg_reg[0] = float4{ 0, 0, 0, 0 };
					b_ldg_reg[1] = float4{ 0, 0, 0, 0 };
				}


#pragma unroll
				for (int i = 0; i < 4; ++i) {
					if ((threadIdx.x % 32) % 4 + (-k_tiles * 4 + k / 2) < k && blockIdx.y * 32 + (threadIdx.x % 32) / 4 * 4 + i < m) {
						ldg32_nc_0(a_ldg_reg[i], (const char *)(A + from_a) + i * k * sizeof(float));
					}
					else {
						a_ldg_reg[i] = 0;
					}
				}

				//                 printf("mmm%f %f %f %f th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
			}

			// FFMA loop
#pragma unroll
			for (int i = 0; i < 8; ++i) {
#pragma unroll
				for (int j = 0; j < 8; ++j) {
					C_frag[i][j] += A_frag[k_frag % 2][i] *
						B_frag[k_frag % 2][j];
					//                     if(C_frag[i][j]!=0 && A_frag[k_frag % 2][i] *
					//                                     B_frag[k_frag % 2][j]!=0 && threadIdx.x==0&&blockIdx.x==0){
					//                         printf("00C_frag[%d][%d]=%f  <=  A_frag[%d][%d]=%f  *  B_frag[%d][%d]=%f\n", i, j, C_frag[i][j], k_frag%2, i, A_frag[k_frag % 2][i], k_frag%2, j, B_frag[k_frag % 2][j]);
					//                     }
				}
			}
		}
	}
	// 这样最后一个循环就不需要再预读取了。确实。最后一轮预取是没有必要的
	// FFMA for the last tile
#pragma unroll
	for (int k_frag = 0; k_frag < 4; ++k_frag) {
		if (k_frag < 3) {
			// load next A&B fragment from shared memory to register
			lds128(A_frag[(k_frag + 1) % 2][0],
				A_frag[(k_frag + 1) % 2][1],
				A_frag[(k_frag + 1) % 2][2],
				A_frag[(k_frag + 1) % 2][3],
				A_lds_addr + (k_frag + 1) % 4 * 36 * sizeof(float));
			lds128(A_frag[(k_frag + 1) % 2][4],
				A_frag[(k_frag + 1) % 2][5],
				A_frag[(k_frag + 1) % 2][6],
				A_frag[(k_frag + 1) % 2][7],
				A_lds_addr + ((k_frag + 1) % 4 * 36 + 16) * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][0],
				B_frag[(k_frag + 1) % 2][1],
				B_frag[(k_frag + 1) % 2][2],
				B_frag[(k_frag + 1) % 2][3],
				B_lds_addr + (k_frag + 1) % 4 * 64 * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][4],
				B_frag[(k_frag + 1) % 2][5],
				B_frag[(k_frag + 1) % 2][6],
				B_frag[(k_frag + 1) % 2][7],
				B_lds_addr + ((k_frag + 1) % 4 * 64 + 32) * sizeof(float));
		}

		// FFMA loop
#pragma unroll
		for (int i = 0; i < 8; ++i) {
#pragma unroll
			for (int j = 0; j < 8; ++j) {
				C_frag[i][j] += A_frag[k_frag % 2][i] *
					B_frag[k_frag % 2][j];
				//                 if (threadIdx.x == 0 && blockIdx.x == 0) {
				//                     printf("11C_frag[%d][%d]=%f  <=  A_frag[%d][%d]=%f  *  B_frag[%d][%d]=%f\n", i, j, C_frag[i][j], k_frag % 2, i, A_frag[k_frag % 2][i], k_frag % 2, j, B_frag[k_frag % 2][j]);
				//                 }
			}
		}
	}

	//     if(threadIdx.x==15){
	//         for(int ii=0;ii<8;ii++){
	//             for(int jj=0;jj<8;jj++){
	//                 if(C_frag[ii][jj]!=0){
	//                     printf("%d,%dC_frag[%d][%d]=%f\n",threadIdx.x, threadIdx.y, ii, jj, C_frag[ii][jj]);
	//                 }
	//             }
	//         }
	//     }




			// C_tile write back, reuse A&B tile shared memory buffer
	uint32_t C_sts_addr = smem_u32addr((float4 *)(smem + warp_id * 2048) +
		mma_tid_y * 4 * 8 + mma_tid_x); // 比如，th=1的mma_tid_y * 4 * 8 + mma_tid_x是32，则要乘4（不需要真的写*4，而是float4帮我们自动*4），因为一个th有4行;   再乘4（这由smem_u32addr执行），因为float占4
// 	uint32_t C_lds_ptr = smem_u32addr(A_smem + (mma_tid_y * 4 * 8 + mma_tid_x) * 4 + (warp_id % 2) * 16 * 32);// 为什么没法利用每个thread已经有的reg值？有可能！！每个thread再分配出12个值，原本的不动。然后最后加到新的reg里即可！有时间可以再想想这个！关键是，这个thread被分配来干什么，已经拥有了什么，所以就不需要取这个值。（不过不知道能提速多少）
	uint32_t C_lds_addr = smem_u32addr(A_smem + threadIdx.x / 8 * 32 + (threadIdx.x % 8) * 4);
	//     if(threadIdx.x==64){
	//         printf("loc=%d, pre=%d, lat=%d\n", C_lds_ptr, (mma_tid_y * 4 * 8 + mma_tid_x)*4, (threadIdx.x/32)*16*32);
	//     }
		//const uint32_t C_loc = warp_id / 2;


	uint32_t m_idx = blockIdx.y * 32;
	//uint32_t n_idx = blockIdx.x * 64 + lane_id + (warp_id % 2) * 64;  // 这两个参数指定了当前block的起始写入C的位置。


//  	float *C_stg_ptr = C + m_idx * n + n_idx;

	if (m_idx >= m) {
		return;
	}
	else if (m_idx + 32 <= m) {
		//  		uint32_t n_guard = n < n_idx ? 0 : n - n_idx;

#pragma unroll
		for (int i = 0; i < 2; ++i) {


			for (int j = 0; j < 2; ++j) {
				__syncthreads();

#pragma unroll
				for (int p = 0; p < 4; ++p) {
					sts128(C_frag[i * 4 + p][j * 4],
						C_frag[i * 4 + p][j * 4 + 1],
						C_frag[i * 4 + p][j * 4 + 2],
						C_frag[i * 4 + p][j * 4 + 3],
						C_sts_addr + p * 8 * sizeof(float4));
				}

				__syncthreads();

				//                 if(threadIdx.x==0){
				//                     int line_zero = 0;
				//                     for(int ii=0;ii<16*2;ii++){
				//                         line_zero = 0;
				//                         for(int jj=0;jj<32;jj++){
				//                             if(A_smem[ii*32+jj]!=0){
				//                                 line_zero = 1;
				//                                 printf("C_smem[%d][%d]=%f  ", ii, jj, A_smem[ii*32+jj]);
				//                             }
				//                         }
				//                         if(line_zero == 1){
				//                             printf("\n");
				//                         }
				//                     }
				//                     printf("\n");
				//                 }

				lds128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], C_lds_addr);
				lds128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7], C_lds_addr + 32 * 8 * sizeof(float));
				lds128(B_frag[1][0], B_frag[1][1], B_frag[1][2], B_frag[1][3],
					C_lds_addr + (32 * 16) * sizeof(float));
				lds128(B_frag[1][4], B_frag[1][5], B_frag[1][6], B_frag[1][7],
					C_lds_addr + (32 * 16) * sizeof(float) + 32 * 8 * sizeof(float));

				// 				if(threadIdx.x==0){
				// 				    printf("i=%d, j=%d, to_add %f %f %f %f, %f %f %f %f,%f %f %f %f,%f %f %f %f\n", i, j, B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7], B_frag[1][0], B_frag[1][1], B_frag[1][2], B_frag[1][3], B_frag[1][4], B_frag[1][5], B_frag[1][6], B_frag[1][7]);
				// 				}

				B_frag[0][0] += B_frag[1][0];
				B_frag[0][1] += B_frag[1][1];
				B_frag[0][2] += B_frag[1][2];
				B_frag[0][3] += B_frag[1][3];

				B_frag[0][4] += B_frag[1][4];
				B_frag[0][5] += B_frag[1][5];
				B_frag[0][6] += B_frag[1][6];
				B_frag[0][7] += B_frag[1][7];

				// 				if(threadIdx.x==0){
				// 				    printf("i=%d, j=%d, final_add %f %f %f %f, %f %f %f %f\n", i, j, B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7]);
				// 				}

				if (blockIdx.x * 64 + (threadIdx.x % 8) * 4 + j * 32 < n) {
					if (blockIdx.y * 32 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32 < m) {
						stg128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], C + (blockIdx.y * 32 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32)*n + blockIdx.x * 64 + (threadIdx.x % 8) * 4 + j * 32);  // 先存前32*32部分。
					}
					if (blockIdx.y * 32 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32 + 8 < m) {
						stg128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7], C + (blockIdx.y * 32 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32 + 8)*n + blockIdx.x * 64 + (threadIdx.x % 8) * 4 + j * 32);  // 先存前32*32部分。
					} // 此处一开始写成else if，和上面的形成二选一格局。
				}
			}
		}
	}
	//	else {
	//#pragma unroll
	//		for (int i = 0; i < 2; ++i) {
	//#pragma unroll
	//			for (int j = 0; j < 2; ++j) {
	//				StgFrag stg_frag(C_frag, j, i);

	//				C_tile_wb(stg_frag,
	//					C_stg_ptr + i * 16 * n + j * 32,
	//					C_lds_ptr,
	//					C_sts_addr,
	//					m,
	//					n,
	//					m_idx + i * 16,
	//					n_idx + j * 32);
	//			}
	//		}
	//	}
}






//float* random_matrix(int row, int col) {
//	float* mat = new float[row * col];
//
//
//	for (int i = 0; i < row; ++i) {
//		for (int j = 0; j < col; ++j) {
//			if (i * col + j + 1 < 10) {
//				mat[i * col + j] = i * col + j + 1;
//			}
//			else {
//				mat[i * col + j] = 0.5;
//			}
//		}
//	}
//
//	return mat;
//}

float* random_matrix(int row, int col) {
	float* mat = new float[row * col];


	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			mat[i * col + j] = 0;
		}
	}

	return mat;
}


void print_mat(float* mat, int row, int col) {
	/*Display the matrix for visualizatoin*/
	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			cout << mat[i * col + j] << " ";
		}cout << endl;
	}
	cout << "\n" << endl;
}



int main()
{
	const int m = 3072, k = 3072, n = 64;
	float* a = random_matrix(m, k);
	float* b = random_matrix(k, n);
	float* c = new float[m*n];

	float* dev_a, *dev_b, *dev_c;

	cudaMalloc((void**)&dev_a, m * k * sizeof(float));
	cudaMalloc((void**)&dev_b, k * n * sizeof(float));
	cudaMalloc((void**)&dev_c, m * n * sizeof(float));

	cudaMemcpy(dev_a, a, m * k * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, b, k * n * sizeof(float), cudaMemcpyHostToDevice);


	constexpr int BLOCK = 64;
	dim3 grid((n + BLOCK - 1) / BLOCK, (m + 32 - 1) / 32);
	int repeat = 1;


	cudaEvent_t start, stop;
	cudaEventCreate(&start);
	cudaEventCreate(&stop);
	cudaEventRecord(start);
	cudaEventQuery(start);

	for (int i = 0; i < repeat; i++) {
		sgemm_128x128x8 << <grid, 64 >> > (m, n, k, dev_a, dev_b, dev_c);
	}


	cudaEventRecord(stop);
	cudaEventSynchronize(stop);
	float elapsed_time;
	cudaEventElapsedTime(&elapsed_time, start, stop);
	printf("Time = %g ms .\n", elapsed_time / repeat);
	cudaEventDestroy(start);
	cudaEventDestroy(stop);


	cudaMemcpy(c, dev_c, m * n * sizeof(float), cudaMemcpyDeviceToHost);

	//cout << 'a' << endl;
	//print_mat(a, m, k);
	//cout << 'b' << endl;
	//print_mat(b, k, n);
	//cout << 'c' << endl;
	//print_mat(c, m, n);
}
