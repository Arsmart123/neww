#include<iostream>
using namespace std;
#include <cstdint>
#include <cstdlib>
#include <cstdio>
#include <cmath>
#include <vector>

#define FETCH_FLOAT4(pointer) (reinterpret_cast<float4*>(&(pointer))[0])

__device__ __forceinline__
uint32_t smem_u32addr(const void *smem_ptr) {
	uint32_t addr;
	asm("{.reg .u64 u64addr;\n"
		" cvta.to.shared.u64 u64addr, %1;\n"
		" cvt.u32.u64 %0, u64addr;}\n"
		: "=r"(addr)
		: "l"(smem_ptr)
	);

	return addr;
}

__device__ __forceinline__
void ldg32_nc(float &reg, const void *ptr, bool guard) {
	asm volatile (
		"{.reg .pred p;\n"
		" setp.ne.b32 p, %2, 0;\n"
#if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 && \
    __CUDA_ARCH__ >= 750
		" @p ld.global.nc.L2::128B.f32 %0, [%1];}\n"
#else
		" @p ld.global.nc.f32 %0, [%1];}\n"
#endif
		: "=f"(reg)
		: "l"(ptr), "r"((int)guard)
		);
}

// __device__ __forceinline__
// void ldg32_nc_0(float &reg, const void *ptr, bool guard) {
//     asm volatile (
//         "{.reg .pred p;\n"
//         " setp.ne.b32 p, %2, 0;\n"
//         " @!p mov.b32 %0, 0;\n"
// #if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 && \
//     __CUDA_ARCH__ >= 750
//         " @p ld.global.nc.L2::128B.f32 %0, [%1];}\n"
// #else
//         " @p ld.global.nc.f32 %0, [%1];}\n"
// #endif
//         : "=f"(reg)
//         : "l"(ptr), "r"((int)guard)
//     );
// }


__device__ __forceinline__ void ldg32_nc_0(float &reg, const void *ptr) {
	asm volatile("{mov.b32 %0, 0;\n"
#if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 &&                 \
    __CUDA_ARCH__ >= 750
		"ld.global.nc.L2::128B.f32 %0, [%1];}\n"
#else
		"ld.global.nc.f32 %0, [%1];}\n"
#endif
		: "=f"(reg)
		: "l"(ptr));
}


__device__ __forceinline__
void stg32(const float &reg, void *ptr, bool guard) {
	asm volatile (
		"{.reg .pred p;\n"
		" setp.ne.b32 p, %2, 0;\n"
		" @p st.global.f32 [%0], %1;}\n"
		: : "l"(ptr), "f"(reg), "r"((int)guard)
		);
}

__device__ __forceinline__
void lds128(float &reg0, float &reg1,
	float &reg2, float &reg3,
	const uint32_t &addr) {
	asm volatile (
		"ld.shared.v4.f32 {%0, %1, %2, %3}, [%4];\n"
		: "=f"(reg0), "=f"(reg1), "=f"(reg2), "=f"(reg3)
		: "r"(addr)
		);
}

__device__ __forceinline__
void sts32(const float &reg, const uint32_t &addr) {
	asm volatile (
		"st.shared.f32 [%0], %1;\n"
		: : "r"(addr), "f"(reg)
		);
}

__device__ __forceinline__
void sts128(const float &reg0, const float &reg1,
	const float &reg2, const float &reg3,
	const uint32_t &addr) {
	asm volatile (
		"st.shared.v4.f32 [%0], {%1, %2, %3, %4};\n"
		: : "r"(addr), "f"(reg0), "f"(reg1), "f"(reg2), "f"(reg3)
		);
}


__device__ __forceinline__
void sts64(const float &reg0, const float &reg1,
	const uint32_t &addr) {
	asm volatile (
		"st.shared.v2.f32 [%0], {%1, %2};\n"
		: : "r"(addr), "f"(reg0), "f"(reg1)
		);
}


struct StgFrag {
	float data[4][4];

	__device__ __forceinline__
		StgFrag(const float(&C_frag)[8][8], int tile_x, int tile_y) {
#pragma unroll
		for (int i = 0; i < 4; ++i) {
#pragma unroll
			for (int j = 0; j < 4; ++j) {
				data[i][j] = C_frag[tile_y * 4 + i][tile_x * 4 + j];
			}
		}
	}
};

__device__ __noinline__
void C_tile_wb(StgFrag C_frag,
	float *C_stg_ptr,
	const float *C_lds_ptr,
	uint32_t C_sts_addr,
	uint32_t m,
	uint32_t n,
	uint32_t m_idx,
	uint32_t n_idx) {
	__syncthreads();

#pragma unroll
	for (int i = 0; i < 4; ++i) {
		sts128(C_frag.data[i][0],
			C_frag.data[i][1],
			C_frag.data[i][2],
			C_frag.data[i][3],
			C_sts_addr + i * 8 * sizeof(float4));
	}

	__syncthreads();

	uint32_t m_guard = m < m_idx ? 0 : m - m_idx;

#pragma unroll
	for (int i = 0; i < 16; ++i) {
		stg32(C_lds_ptr[i * 32],
			C_stg_ptr + i * n,
			i < m_guard && n_idx < n);
	}
}


__device__ __forceinline__ void stg128(const float &reg0, const float &reg1,
	const float &reg2, const float &reg3,
	const float *addr) {
	asm volatile("st.global.v4.f32 [%0], {%1, %2, %3, %4};\n"
		:
	: "l"(addr), "f"(reg0), "f"(reg1), "f"(reg2), "f"(reg3));
}

/*
 * matrix A, B and C: row-major
 *
 * mma block:
 * thread block tile: m128n128k8
 * warp tile: m32n64k8
 * thread tile: m8n8k8
 * thread fragment:
 *     matrixA: 8x1 FP32
 *     matrixB: 1x8 FP32
 *
 * ----------------------------------------------------------------
 * thread block tile map:
 *
 *                                128
 *                    --|---------------------|
 *             B_tile  8|                     |
 *                    --|---------------------|
 *
 *  A_tile   | 8 |      |    64    |
 *         --|---|    --|----------|----------|
 *           |   |    32|  warp_0  |  warp_1  |
 *           |   |    --|----------|----------|
 *           |   |      |  warp_2  |  warp_3  |
 *        128|   |      |----------|----------|
 *           |   |      |  warp_4  |  warp_5  |
 *           |   |      |----------|----------|
 *           |   |      |  warp_6  |  warp_7  |
 *         --|---|      |----------|----------|
 *
 * ----------------------------------------------------------------
 * warp tile map:
 *
 * 'z' thread map to avoid LDS.128 shared memory broadcast limitation.
 *
 *              |              32               ||
 *     B_frag --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
 *             1|///|   |   |   |   |   |   |   ||///|   |   |   |   |   |   |   |
 *            --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
 * A_frag       | 4 |                           ||
 *    | 1 |                                     ||
 *  --|---|--   |---|---|---|---|---|---|---|---||---|---------------------------|
 *    |///|4    |t0 |t2 |t4 |t6 |t8 |t10|t12|t14||t0 |                           |
 *    |---|--   |---|---|---|---|---|---|---|---||---|                           |
 *    |   |     |t1 |t3 |t5 |t7 |t9 |t11|t13|t15||                               |
 *  16|---|     |---|---|---|---|---|---|---|---||                               |
 *    |   |     |t16|t18|t20|t22|t24|t26|t28|t30||                               |
 *    |---|     |---|---|---|---|---|---|---|---||                               |
 *    |   |     |t17|t19|t21|t23|t25|t27|t29|t31||                               |
 *  ==|===|=====|===|===|===|===|===|===|===|===||===|============================
 *    |///|     |t0 |                           ||t0 |                           |
 *    |---|     |---|                           ||---|                           |
 *    |   |     |                               ||                               |
 *    |---|     |                               ||                               |
 *    |   |     |                               ||                               |
 *    |---|     |                               ||                               |
 *    |   |     |                               ||                               |
 *    |---|     |-------------------------------||-------------------------------|
 *
 */
__global__ __launch_bounds__(256, 2) void sgemm_128x128x8(uint32_t m,
	uint32_t n,
	uint32_t k,
	float *A,
	float *B,
	float *C) {
	/*
	 * matrix A & B thread block tile shared memory (double buffer)
	 * matrix A: 132 * 8 * 4Byte/item * double buffer = 4.125KB * 2
	 * matrix B: 128 * 8 * 4Byte/item * double buffer = 8KB
	 *
	 * for double buffer faster switch, A_smem requires 8KB * 2 shared memory
	 * and 16KB aligned, B_smem should be 8KB aligned, then the double buffer
	 * can be switched by only 1 xor instruction:
	 *     (uint32_t &)A_smem ^= 0x2000;
	 *     (uint32_t &)B_smem ^= 0x1000;
	 */
	 //     36*32*4/1024=4.5  (36+64)*?*4*2/1024<32  ?<32*1024/4/2/100 = 40.96 再大就没法算了。。
	 //     64*32*4/1024=8
	 //     （4.5+8）*2=25KB

	__shared__ __align__(8 * 1024) char smem[25 * 1024];  // 额。。对齐设置为多少才好呢。。？先这样吧，之后试试看增大共享内存会不会有影响。。
	float *A_smem = reinterpret_cast<float *>(smem);
	float *B_smem = reinterpret_cast<float *>(smem + 9 * 1024);

	// A, B and C register fragment
	float A_frag[2][8];
	float B_frag[2][4];
	float C_frag[8][4];
#pragma unroll
	for (int i = 0; i < 8; ++i) {
#pragma unroll
		for (int j = 0; j < 4; ++j) {
			C_frag[i][j] = 0;
		}
	}

	const uint32_t lane_id = threadIdx.x % 32;
	const uint32_t warp_id = threadIdx.x / 32;

	// 4x8 threads each warp for FFMA
	const uint32_t mma_tid_x = (lane_id / 2) % 8;
	const uint32_t mma_tid_y = (lane_id / 16) * 2 + (lane_id % 2);

	// A_tile & B_tile ldg pointer
	int from_a = (blockIdx.y * 32 + (threadIdx.x % 64) / 8 * 4) * k + (threadIdx.x % 64) % 8 + (threadIdx.x / 64) * (k / 4);
	int from_b = ((threadIdx.x % 64) / 16 + (threadIdx.x / 64) * (k / 4)) * n + blockIdx.x * 64 + (threadIdx.x % 64) % 16 * 4;
	//     if(threadIdx.x==64){
	//         printf("loc_int=%d\n", from_b);
	//     }
		// A_tile & B_tile sts/lds pointer
		// using uint32_t pointer for faster double buffer switch

	uint32_t A_lds_addr = smem_u32addr(
		A_smem + mma_tid_y * 4 + (threadIdx.x / 64) * 36 * 8);  //这里是36！！！我还搞忘了一开始
	uint32_t B_lds_addr = smem_u32addr(
		B_smem + (warp_id % 2) * 32 + mma_tid_x * 4 + (threadIdx.x / 64) * 64 * 8);  // 读取共享内存，存到寄存器去

	float4 b_ldg_reg0;
	float4 b_ldg_reg1;
	float a_ldg_reg[4];


	uint32_t a_sts_addr = smem_u32addr(A_smem + ((threadIdx.x % 64) % 8) * 36 + ((threadIdx.x % 64) / 8) * 4 + (threadIdx.x / 64) * 36 * 8);
	uint32_t b_sts_addr = smem_u32addr(B_smem + ((threadIdx.x % 64) / 16) * 64 + ((threadIdx.x % 64) % 16) * 4 + (threadIdx.x / 64) * 64 * 8);
	// 1'st A&B tile loaded before the k_tile loop
// 	暂且不考虑slice的情况。。
	uint32_t k_tiles = (k / 4 + 7) / 8 - 1;
	uint32_t first_k_tile = k / 4 - k_tiles * 8 + (k / 4)*(threadIdx.x / 64); // 对每个warp而言，此first_K_tile代表的是各自第一次计算后所能达到的位置，是一个门槛的位置，而不是每次前进的长度
// 	if(threadIdx.x==64){
// 	    printf("first_k = %d\n", first_k_tile);
// 	}
	// load 1'st tile to shared memory
	{
		// load first
		// load gmem to smem for ashare
// 		if(threadIdx.x==0&&blockIdx.x==0){
// 		    printf("first_k_tile=%d\n", first_k_tile);
// 		}
#pragma unroll
		for (int i = 0; i < 4; ++i) {
			if ((threadIdx.x % 64) % 8 + (threadIdx.x / 64)*(k / 4) < first_k_tile  &&  blockIdx.y * 32 + (threadIdx.x % 64) / 8 * 4 + i < m) {
				ldg32_nc_0(a_ldg_reg[i], (const char *)(A + from_a) + i * k * sizeof(float));
				//printf("th=%d, Ashare=%f, %f, aa %d < aa1 %d, aa2 %d < aa3 %d\n", threadIdx.x, a_ldg_reg[0], a_ldg_reg[1], (threadIdx.x % 64) % 4, first_k_tile ,  blockIdx.y * 32 + (threadIdx.x % 64) / 4 * 2 + i, m);
			}
			else {
				a_ldg_reg[i] = 0;
			}
		}
		//		// 		printf("%f %f %f %f th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
		sts128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], a_sts_addr);

		//if (threadIdx.x == 16) {
		//	printf("a1=%d < a2=%d, a3=%d<a4=%d\n", from_b , (1 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n , (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4) , first_k_tile);
		//}
		// load gmem to smem for bshare


		if (from_b < (1 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n && (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4) < first_k_tile) {
			b_ldg_reg0 = FETCH_FLOAT4(B[from_b]);
			//if (threadIdx.x == 96) {
			//	printf("th=%d, Bshare=%f, %f, %f, %f, aa %d < aa1 %d, aa2 %d < aa3 %d\n", threadIdx.x, b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w, from_b, (1 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n, (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4), first_k_tile);
			//}
		}
		else {
			b_ldg_reg0 = float4{ 0, 0, 0, 0 };
		}

		FETCH_FLOAT4(B_smem[((threadIdx.x % 64) / 16) * 64 + ((threadIdx.x % 64) % 16) * 4 + (threadIdx.x / 64) * 64 * 8]) = b_ldg_reg0;



		// 		if (threadIdx.x == 0) {
		// 			printf("a1=%d < a2=%d, a3=%d < a4=%d\n", from_b+n*4 , (5 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n , (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4)+4 , first_k_tile);
		// 		}
		if (from_b + n * 4 < (5 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n && (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4) + 4 < first_k_tile) {
			b_ldg_reg1 = FETCH_FLOAT4(B[from_b + n * 4]);
			//if (threadIdx.x == 96) {
			//	printf("11th=%d, Bshare=%f, %f, %f, %f, aa %d < aa1 %d, aa2 %d < aa3 %d\n", threadIdx.x, b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w, from_b, (1 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n, (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4), first_k_tile);
			//}
		}
		else {
			b_ldg_reg1 = float4{ 0, 0, 0, 0 };
		}
		//if (((threadIdx.x % 64) / 8) * 64 + ((threadIdx.x % 64) % 8) * 8 + (threadIdx.x / 64) * 64 * 8 + 4 == 64*2+4) {
		//	printf("16loc======%f, %f, %f, %f, thread=%d\n", b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w, threadIdx.x);
		//}
		FETCH_FLOAT4(B_smem[((threadIdx.x % 64) / 16) * 64 + ((threadIdx.x % 64) % 16) * 4 + (threadIdx.x / 64) * 64 * 8 + 64 * 4]) = b_ldg_reg1;
		__syncthreads();
		//if (threadIdx.x == 1) {
		//	printf("Bshare=%f, %f, %f, %f\n", B_smem[0], B_smem[1], B_smem[2], B_smem[3]);
		//}
		// add offset and flip flag
		from_a += k / 4 - k_tiles * 8;
		from_b += (k / 4 - k_tiles * 8) * n;
		//         if(threadIdx.x==32&&blockIdx.x==0){
		//             printf("add=%d, from_b=%d\n", first_k_tile * n, from_b);
		//         }
		a_sts_addr += 36 * 8 * 4 * sizeof(float);
		b_sts_addr += 64 * 8 * 4 * sizeof(float);
	}


	//     if(threadIdx.x==0){
	//         printf("hahaha=%f\n", A_smem[10]);
	//     }

	// 	if (threadIdx.x == 0 && blockIdx.x == 0) {
	// // 		for (int ii = 0; ii < 32; ii++) {
	// // 			for (int jj = 0; jj < 32; jj++) {
	// // 				if (A_smem[ii * 36 + jj] != 0) {
	// // 					printf("A_smem[%d][%d]=%f  ", ii, jj, A_smem[ii * 36 + jj]);
	// // 				}
	// // 			}
	// // 			printf("\n");
	// // 		}
	// // 		printf("\n");
	//
	// 		for (int ii = 0; ii < 32; ii++) {
	// 			for (int jj = 0; jj < 64; jj++) {
	// 				if (B_smem[ii * 64 + jj] != 0) {
	// 					printf("B_smem[%d][%d]=%f  ", ii, jj, B_smem[ii * 64 + jj]);
	// 				}
	// 			}
	// 			printf("\n");
	// 		}
	// 		printf("\n");
	// // 		__syncthreads();  // 奇怪。。加太多sync会卡死。。。最后一个sync都不加，正常运行
	// 	}

		// load 1'st fragment
	lds128(A_frag[0][0], A_frag[0][1], A_frag[0][2], A_frag[0][3],
		A_lds_addr);
	lds128(A_frag[0][4], A_frag[0][5], A_frag[0][6], A_frag[0][7],
		A_lds_addr + 16 * sizeof(float));
	lds128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3],
		B_lds_addr);
	// 	lds128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7],
	// 		B_lds_addr + 32 * sizeof(float));

// 	if (threadIdx.x == 96 || threadIdx.x==128||threadIdx.x==160||threadIdx.x==224) {
//     if (threadIdx.x == 96) {
// 		for (int ii = 0; ii < 8; ii++) {
// 			printf("A_frag[%d]=%f  ", ii, A_frag[0][ii]);
// 		}
// 		printf("\n");
// 		for (int ii = 0; ii < 4; ii++) {
// 			printf("B_frag[%d]=%f  ", ii, B_frag[0][ii]);
// 		}
// 		printf("\n");
// 	}
//     for (int ii = 0; ii < 8; ii++) {
//         if(A_frag[0][ii]!=0){
//             printf("[%d]A_frag[%d]=%f  ",threadIdx.x,  ii, A_frag[0][ii]);
//         }
//     }
//     printf("\n");



	int jump = 0;
	// k_tiles loop
	for (; k_tiles > 0; --k_tiles) {
		// 	    if(threadIdx.x==0){
		// 	        printf("k_tiles=%d, \n", k_tiles);
		// 	    }
		jump ^= 1;
#pragma unroll
		for (int k_frag = 0; k_frag < 8; ++k_frag) {
			// store next A&B tile to shared memory
			if (k_frag == 7) {
				sts128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], a_sts_addr);
				sts128(b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w, b_sts_addr);
				sts128(b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w, b_sts_addr + 4 * 64 * sizeof(float));
				__syncthreads();

				//                 if(threadIdx.x==0 && blockIdx.x==0){
				//
				// //                     for(int ii=0;ii<8;ii++){
				// //                         for(int jj=0;jj<32;jj++){
				// //                             if(A_smem[ii*36+jj+36*4*2*4*jump]!=0){
				// //                                 printf("11A_smem[%d][%d]=%f  ", ii, jj, A_smem[ii*36+jj+36*4*2*4*jump]);
				// //                             }
				// //                         }
				// //                         printf("\n");
				// //                     }
				// //                     printf("\n");
				//
				//
				//                     for(int ii=0;ii<32;ii++){
				//                         for(int jj=0;jj<64;jj++){
				//                             if(B_smem[ii*64+jj+64*8*4*jump]!=0){
				//                                 printf("11B_smem[%d][%d]=%f  ", ii, jj, B_smem[ii*64+jj+64*8*4*jump]);
				//                             }
				//                         }
				//                         printf("\n");
				//                     }
				//                     printf("\n");
				//                 }

								// switch double buffer
				if (jump == 1) {
					A_lds_addr += 36 * 8 * 4 * sizeof(float);
					B_lds_addr += 64 * 8 * 4 * sizeof(float);
					a_sts_addr -= 36 * 8 * 4 * sizeof(float);
					b_sts_addr -= 64 * 8 * 4 * sizeof(float);
				}
				else {
					A_lds_addr -= 36 * 8 * 4 * sizeof(float);
					B_lds_addr -= 64 * 8 * 4 * sizeof(float);
					a_sts_addr += 36 * 8 * 4 * sizeof(float);
					b_sts_addr += 64 * 8 * 4 * sizeof(float);
				}
				//if (threadIdx.x == 0) {
				//	printf("A_lds_addr=%u, new_A=%u\n", A_lds_addr, A_lds_addr + 132 * 8 * 4);
				//}
				// ldg pointer for next tile
				from_a += 8;
				from_b += 8 * n;
			}

			// load next A&B fragment from shared memory to register
			lds128(A_frag[(k_frag + 1) % 2][0],
				A_frag[(k_frag + 1) % 2][1],
				A_frag[(k_frag + 1) % 2][2],
				A_frag[(k_frag + 1) % 2][3],
				A_lds_addr + (k_frag + 1) % 8 * 36 * sizeof(float));
			lds128(A_frag[(k_frag + 1) % 2][4],
				A_frag[(k_frag + 1) % 2][5],
				A_frag[(k_frag + 1) % 2][6],
				A_frag[(k_frag + 1) % 2][7],
				A_lds_addr + ((k_frag + 1) % 8 * 36 + 16) * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][0],
				B_frag[(k_frag + 1) % 2][1],
				B_frag[(k_frag + 1) % 2][2],
				B_frag[(k_frag + 1) % 2][3],
				B_lds_addr + (k_frag + 1) % 8 * 64 * sizeof(float));
			// 			lds128(B_frag[(k_frag + 1) % 2][4],
			// 				B_frag[(k_frag + 1) % 2][5],
			// 				B_frag[(k_frag + 1) % 2][6],
			// 				B_frag[(k_frag + 1) % 2][7],
			// 				B_lds_addr + ((k_frag + 1) % 4 * 64 + 32) * sizeof(float));
//             if(threadIdx.x==64){
//                 printf("reg_for[%d], %f %f %f %f, %f %f %f %f, %f %f %f %f\n", threadIdx.x, A_frag[(k_frag + 1) % 2][0],
// 				A_frag[(k_frag + 1) % 2][1],
// 				A_frag[(k_frag + 1) % 2][2],
// 				A_frag[(k_frag + 1) % 2][3],
// 				 A_frag[(k_frag + 1) % 2][4],
// 				A_frag[(k_frag + 1) % 2][5],
// 				A_frag[(k_frag + 1) % 2][6],
// 				A_frag[(k_frag + 1) % 2][7],
// 				B_frag[(k_frag + 1) % 2][0],
// 				B_frag[(k_frag + 1) % 2][1],
// 				B_frag[(k_frag + 1) % 2][2],
// 				B_frag[(k_frag + 1) % 2][3]);
//             }
						// load next A&B tile
			if (k_frag == 0) {
				if (from_b < (1 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n + (-k_tiles * 8 + k / 4)*n && (-k_tiles * 8 + k / 4) + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4) < (threadIdx.x / 64 + 1)*(k / 4)) {

					b_ldg_reg0 = FETCH_FLOAT4(B[from_b]);
					// 				    if(threadIdx.x==0){
					// 				        printf("readB0=%f %f %f %f\n", b_ldg_reg0.x,b_ldg_reg0.y,b_ldg_reg0.z,b_ldg_reg0.w);
					// 				    }
				}
				else {
					b_ldg_reg0 = float4{ 0, 0, 0, 0 };
				}


				if (from_b + 4 * n < (5 + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4))*n + +(-k_tiles * 8 + k / 4)*n && (-k_tiles * 8 + k / 4) + (threadIdx.x % 64) / 16 + (threadIdx.x / 64)*(k / 4) + 4 < (threadIdx.x / 64 + 1)*(k / 4)) {

					b_ldg_reg1 = FETCH_FLOAT4(B[from_b + 4 * n]);
					// 				    if(threadIdx.x==0){
					// 				        printf("readB1=%f %f %f %f\n", b_ldg_reg1.x,b_ldg_reg1.y,b_ldg_reg1.z,b_ldg_reg1.w);
					// 				    }
				}
				else {
					b_ldg_reg1 = float4{ 0, 0, 0, 0 };
				}

#pragma unroll
				for (int i = 0; i < 4; ++i) {
					if ((threadIdx.x % 64) % 8 + (threadIdx.x / 64)*(k / 4) + (-k_tiles * 8 + k / 4) < k && blockIdx.y * 32 + (threadIdx.x % 64) / 8 * 4 + i < m) {
						ldg32_nc_0(a_ldg_reg[i], (const char *)(A + from_a) + i * k * sizeof(float));
					}
					else {
						a_ldg_reg[i] = 0;
					}
				}


			}

			// FFMA loop
#pragma unroll
			for (int i = 0; i < 8; ++i) {
#pragma unroll
				for (int j = 0; j < 4; ++j) {
					C_frag[i][j] += A_frag[k_frag % 2][i] *
						B_frag[k_frag % 2][j];
					//                     if(threadIdx.x==66 && C_frag[i][j] != 0 && A_frag[k_frag % 2][i] * B_frag[k_frag % 2][j] != 0 && blockIdx.x == 0) {
					//                         printf("[%d]00C_frag[%d][%d]=%f  <=  A_frag[%d][%d]=%f  *  B_frag[%d][%d]=%f\n",threadIdx.x, i, j, C_frag[i][j], k_frag % 2, i, A_frag[k_frag % 2][i], k_frag % 2, j, B_frag[k_frag % 2][j]);
					//                     }
				}
			}
		}
	}
	// 这样最后一个循环就不需要再预读取了。确实。最后一轮预取是没有必要的
	// FFMA for the last tile
#pragma unroll
	for (int k_frag = 0; k_frag < 8; ++k_frag) {
		if (k_frag < 7) {
			// load next A&B fragment from shared memory to register
			lds128(A_frag[(k_frag + 1) % 2][0],
				A_frag[(k_frag + 1) % 2][1],
				A_frag[(k_frag + 1) % 2][2],
				A_frag[(k_frag + 1) % 2][3],
				A_lds_addr + (k_frag + 1) % 8 * 36 * sizeof(float));
			lds128(A_frag[(k_frag + 1) % 2][4],
				A_frag[(k_frag + 1) % 2][5],
				A_frag[(k_frag + 1) % 2][6],
				A_frag[(k_frag + 1) % 2][7],
				A_lds_addr + ((k_frag + 1) % 8 * 36 + 16) * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][0],
				B_frag[(k_frag + 1) % 2][1],
				B_frag[(k_frag + 1) % 2][2],
				B_frag[(k_frag + 1) % 2][3],
				B_lds_addr + (k_frag + 1) % 8 * 64 * sizeof(float));
			// 			lds128(B_frag[(k_frag + 1) % 2][4],
			// 				B_frag[(k_frag + 1) % 2][5],
			// 				B_frag[(k_frag + 1) % 2][6],
			// 				B_frag[(k_frag + 1) % 2][7],
			// 				B_lds_addr + ((k_frag + 1) % 4 * 64 + 32) * sizeof(float));
		}
		// 		if(threadIdx.x==66){
		//             printf("sssss-%f %f %f %f,%f %f %f %f,%f %f %f %f, th=%d\n", A_frag[(k_frag + 1) % 2][0],
		//                     A_frag[(k_frag + 1) % 2][1],
		//                     A_frag[(k_frag + 1) % 2][2],
		//                     A_frag[(k_frag + 1) % 2][3],
		//                     A_frag[(k_frag + 1) % 2][4],
		//                     A_frag[(k_frag + 1) % 2][5],
		//                     A_frag[(k_frag + 1) % 2][6],
		//                     A_frag[(k_frag + 1) % 2][7],
		//                     B_frag[(k_frag + 1) % 2][0],
		//                     B_frag[(k_frag + 1) % 2][1],
		//                     B_frag[(k_frag + 1) % 2][2],
		//                     B_frag[(k_frag + 1) % 2][3], threadIdx.x);
		// 	    }

				// FFMA loop
#pragma unroll
		for (int i = 0; i < 8; ++i) {
#pragma unroll
			for (int j = 0; j < 4; ++j) {
				C_frag[i][j] += A_frag[k_frag % 2][i] *
					B_frag[k_frag % 2][j];
				//                 if(threadIdx.x==66 && C_frag[i][j] != 0 && A_frag[k_frag % 2][i] * B_frag[k_frag % 2][j] != 0 && blockIdx.x == 0) {
				//                     printf("[%d]11C_frag[%d][%d]=%f  <=  A_frag[%d][%d]=%f  *  B_frag[%d][%d]=%f\n", threadIdx.x, i, j, C_frag[i][j], k_frag % 2, i, A_frag[k_frag % 2][i], k_frag % 2, j, B_frag[k_frag % 2][j]);
				//                 }
			}
		}
	}
	// 	if (threadIdx.x==66 && blockIdx.x==0 && blockIdx.y==0) {
	// 		for (int ii = 0; ii < 8; ii++) {
	// 			for (int jj = 0; jj < 4; jj++) {
	// 				if (C_frag[ii][jj] != 0) {
	// 					printf("%d,C_frag[%d][%d]=%f\n", threadIdx.x, ii, jj, C_frag[ii][jj]);
	// 				}
	// 			}
	// 		}
	// 	}
	// 	for (int ii = 0; ii < 8; ii++) {
	// 		for (int jj = 0; jj < 8; jj++) {
	// 			C_frag[ii][jj] = threadIdx.x + (ii+1) * 0.1+(jj+1)*0.01;
	// 		}
	// 	}  // special initial value for C_frag, only for test.



		// C_tile write back, reuse A&B tile shared memory buffer
	uint32_t C_sts_addr = smem_u32addr((float4 *)(smem + warp_id * 2048) +
		mma_tid_y * 4 * 8 + mma_tid_x); // 比如，th=1的mma_tid_y * 4 * 8 + mma_tid_x是32，则要乘4（不需要真的写*4，而是float4帮我们自动*4），因为一个th有4行;   再乘4（这由smem_u32addr执行），因为float占4
	uint32_t C_lds_ptr = smem_u32addr(A_smem + (mma_tid_y * 4 * 8 + mma_tid_x) * 4 + (warp_id % 2) * 16 * 32);// 后续从这里，再加3200，取四次。。。。解释：为什么没法利用每个thread已经有的reg值，不，有可能！！每个thread再分配出12个值，原本的不动。然后最后加到新的reg里即可！有时间可以再想想这个！关键是，这个thread被分配来干什么，已经拥有了什么，所以就不需要取这个值。（不过不知道能提速多少）
//     if(threadIdx.x==64){
//         printf("loc=%d, pre=%d, lat=%d\n", C_lds_ptr, (mma_tid_y * 4 * 8 + mma_tid_x)*4, (threadIdx.x/32)*16*32);
//     }
	const uint32_t C_loc = warp_id / 2;


	uint32_t m_idx = blockIdx.y * 32;
	uint32_t n_idx = blockIdx.x * 64 + lane_id + (warp_id % 2) * 32;  // 这两个参数指定了当前block的起始写入C的位置。



	float *C_stg_ptr = C + m_idx * n + n_idx;

	if (m_idx >= m) {
		return;
	}
	else if (m_idx + 32 <= m) {
		uint32_t n_guard = n < n_idx ? 0 : n - n_idx;

#pragma unroll
		for (int i = 0; i < 2; ++i) {
			__syncthreads();


			if (C_loc == 0) {
				sts128(C_frag[i * 4 + 1][0],
					C_frag[i * 4 + 1][1],
					C_frag[i * 4 + 1][2],
					C_frag[i * 4 + 1][3],
					C_sts_addr + 1 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 2][0],
					C_frag[i * 4 + 2][1],
					C_frag[i * 4 + 2][2],
					C_frag[i * 4 + 2][3],
					C_sts_addr + 2 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 3][0],
					C_frag[i * 4 + 3][1],
					C_frag[i * 4 + 3][2],
					C_frag[i * 4 + 3][3],
					C_sts_addr + 3 * 8 * sizeof(float4));
			}
			else if (C_loc == 1) {
				sts128(C_frag[i * 4 + 0][0],
					C_frag[i * 4 + 0][1],
					C_frag[i * 4 + 0][2],
					C_frag[i * 4 + 0][3],
					C_sts_addr + 0 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 2][0],
					C_frag[i * 4 + 2][1],
					C_frag[i * 4 + 2][2],
					C_frag[i * 4 + 2][3],
					C_sts_addr + 2 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 3][0],
					C_frag[i * 4 + 3][1],
					C_frag[i * 4 + 3][2],
					C_frag[i * 4 + 3][3],
					C_sts_addr + 3 * 8 * sizeof(float4));
			}
			else if (C_loc == 2) {
				sts128(C_frag[i * 4 + 0][0],
					C_frag[i * 4 + 0][1],
					C_frag[i * 4 + 0][2],
					C_frag[i * 4 + 0][3],
					C_sts_addr + 0 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 1][0],
					C_frag[i * 4 + 1][1],
					C_frag[i * 4 + 1][2],
					C_frag[i * 4 + 1][3],
					C_sts_addr + 1 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 3][0],
					C_frag[i * 4 + 3][1],
					C_frag[i * 4 + 3][2],
					C_frag[i * 4 + 3][3],
					C_sts_addr + 3 * 8 * sizeof(float4));
			}
			else if (C_loc == 3) {
				sts128(C_frag[i * 4 + 0][0],
					C_frag[i * 4 + 0][1],
					C_frag[i * 4 + 0][2],
					C_frag[i * 4 + 0][3],
					C_sts_addr + 0 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 1][0],
					C_frag[i * 4 + 1][1],
					C_frag[i * 4 + 1][2],
					C_frag[i * 4 + 1][3],
					C_sts_addr + 1 * 8 * sizeof(float4));
				sts128(C_frag[i * 4 + 2][0],
					C_frag[i * 4 + 2][1],
					C_frag[i * 4 + 2][2],
					C_frag[i * 4 + 2][3],
					C_sts_addr + 2 * 8 * sizeof(float4));
			}
			__syncthreads();



			// 			if (threadIdx.x == 0 && i==0) {
			// 				for (int ii0 = 0; ii0 < 128; ii0++) {
			// 					for (int jj0 = 0; jj0 < 32; jj0++) {
			//                         A_smem[ii0 * 32 + jj0] = jj0 + ii0*0.001;
			// 					}
			// 					printf("\n");
			// 				}
			// 				printf("\n");
			// 			}
			// 			__syncthreads();

			//             printf("enter here!");
			// 			if (threadIdx.x == 0 && i==0) {
			// 				for (int ii0 = 0; ii0 < 128; ii0++) {
			// 					for (int jj0 = 0; jj0 < 32; jj0++) {
			// 						if (A_smem[ii0 * 32 + jj0] != 0) {
			// 							printf("sm[%d][%d]=%f  ", ii0, jj0, A_smem[ii0 * 32 + jj0]);
			// 						}
			// 					}
			// 					printf("\n");
			// 				}
			// 				printf("\n");
			// 			}
			__syncthreads();



			// 比如是第一、二个warp，那就不取第一行。比如是第三、四个warp，那就不取第二行
			if (C_loc == 0) {
				lds128(b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,
					C_lds_ptr + 16 * 64 * sizeof(float));
				lds128(b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w,
					C_lds_ptr + 16 * 64 * 2 * sizeof(float));
				lds128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3],
					C_lds_ptr + 16 * 64 * 3 * sizeof(float));
				// 				if (threadIdx.x==32&&i == 0) {
				// 					printf("C_loc=[%d], tttt[%d] - %f %f %f %f,%f %f %f %f,%f %f %f %f,%f %f %f %f\n",  C_loc, threadIdx.x, C_frag[i * 4][0], C_frag[i * 4][1], C_frag[i * 4][2], C_frag[i * 4][3],b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,  b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w, a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3]);
				// 				}  // 两个问题：1. 存进去的时候，也可以分四组，每个组只需要存进去75%的值即可。2. 取出来的时候，每个thread还得按原位置取。不能自由乱取。
				a_ldg_reg[0] += (b_ldg_reg0.x + b_ldg_reg1.x + C_frag[i * 4][0]);
				a_ldg_reg[1] += (b_ldg_reg0.y + b_ldg_reg1.y + C_frag[i * 4][1]);
				a_ldg_reg[2] += (b_ldg_reg0.z + b_ldg_reg1.z + C_frag[i * 4][2]);
				a_ldg_reg[3] += (b_ldg_reg0.w + b_ldg_reg1.w + C_frag[i * 4][3]);
				// 				if(a_ldg_reg[0]+a_ldg_reg[1]+a_ldg_reg[2]+a_ldg_reg[3]!=0){
				//                     printf("0-version-%f, %f, %f, %f, th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
				// 				}
				if (blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32 < n && blockIdx.y * 32 + mma_tid_y * 4 + i * 16 < m) {
					// 				    if(threadIdx.x==32){
					// 				        printf("kkkk %f, %f, %f, %f\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3]);
					// 				    }
					stg128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], C + (blockIdx.y * 32 + mma_tid_y * 4 + i * 16)*n + blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32);
				}
			}
			else if (C_loc == 1) {
				lds128(b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,
					C_lds_ptr + 32 * sizeof(float));
				lds128(b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w,
					C_lds_ptr + 32 * sizeof(float) + 16 * 64 * 2 * sizeof(float));
				lds128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3],
					C_lds_ptr + 32 * sizeof(float) + 16 * 64 * 3 * sizeof(float));
				// 				if (threadIdx.x==64&&i == 0) {
				// 					printf("C_loc=[%d],tttt[%d]-ini_loc=%d - %f %f %f %f,%f %f %f %f,%f %f %f %f,%f %f %f %f\n",  C_loc, threadIdx.x,C_lds_ptr + 32*sizeof(float), b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,  C_frag[i * 4+1][0], C_frag[i * 4+1][1], C_frag[i * 4+1][2], C_frag[i * 4+1][3], b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w, a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3]);
				// 				}
				a_ldg_reg[0] += (b_ldg_reg0.x + b_ldg_reg1.x + C_frag[i * 4 + 1][0]);
				a_ldg_reg[1] += (b_ldg_reg0.y + b_ldg_reg1.y + C_frag[i * 4 + 1][1]);
				a_ldg_reg[2] += (b_ldg_reg0.z + b_ldg_reg1.z + C_frag[i * 4 + 1][2]);
				a_ldg_reg[3] += (b_ldg_reg0.w + b_ldg_reg1.w + C_frag[i * 4 + 1][3]);
				// 				if(a_ldg_reg[0]+a_ldg_reg[1]+a_ldg_reg[2]+a_ldg_reg[3]!=0){
				// 				    printf("1-version-%f, %f, %f, %f, th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
				// 				}
				if (blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32 < n && blockIdx.y * 32 + mma_tid_y * 4 + i * 16 + 1 < m) {
					stg128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], C + (blockIdx.y * 32 + mma_tid_y * 4 + i * 16 + 1)*n + blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32);
				}
			}
			else if (C_loc == 2) {
				lds128(b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,
					C_lds_ptr + 32 * 2 * sizeof(float));
				lds128(b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w,
					C_lds_ptr + 32 * 2 * sizeof(float) + 16 * 64 * 1 * sizeof(float));
				lds128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3],
					C_lds_ptr + 32 * 2 * sizeof(float) + 16 * 64 * 3 * sizeof(float));
				// 				if (i == 0) {
				// 					printf("C_loc=[%d],tttt[%d] - %f %f %f %f,%f %f %f %f,%f %f %f %f,%f %f %f %f\n",  C_loc, threadIdx.x,b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,  b_ldg_reg1.x, b_ldg_reg1.y,b_ldg_reg1.z, b_ldg_reg1.w , C_frag[i * 4+2][0], C_frag[i * 4+2][1], C_frag[i * 4+2][2], C_frag[i * 4+2][3], a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3]);
				// 				}
				a_ldg_reg[0] += (b_ldg_reg0.x + b_ldg_reg1.x + C_frag[i * 4 + 2][0]);
				a_ldg_reg[1] += (b_ldg_reg0.y + b_ldg_reg1.y + C_frag[i * 4 + 2][1]);
				a_ldg_reg[2] += (b_ldg_reg0.z + b_ldg_reg1.z + C_frag[i * 4 + 2][2]);
				a_ldg_reg[3] += (b_ldg_reg0.w + b_ldg_reg1.w + C_frag[i * 4 + 2][3]);
				// 				if(a_ldg_reg[0]+a_ldg_reg[1]+a_ldg_reg[2]+a_ldg_reg[3]!=0){
				// 				    printf("2-version-%f, %f, %f, %f, th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
				// 				}
				if (blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32 < n && blockIdx.y * 32 + mma_tid_y * 4 + i * 16 + 2 < m) {
					stg128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], C + (blockIdx.y * 32 + mma_tid_y * 4 + i * 16 + 2)*n + blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32);
				}
			}
			else if (C_loc == 3) {
				lds128(b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,
					C_lds_ptr + 32 * 3 * sizeof(float));
				lds128(b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w,
					C_lds_ptr + 32 * 3 * sizeof(float) + 16 * 64 * 1 * sizeof(float));
				lds128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3],
					C_lds_ptr + 32 * 3 * sizeof(float) + 16 * 64 * 2 * sizeof(float));
				// 				if (i == 0) {
				// 					printf("C_loc=[%d], tttt[%d] - %f %f %f %f,%f %f %f %f,%f %f %f %f,%f %f %f %f\n",  C_loc, threadIdx.x,b_ldg_reg0.x, b_ldg_reg0.y, b_ldg_reg0.z, b_ldg_reg0.w,  b_ldg_reg1.x, b_ldg_reg1.y, b_ldg_reg1.z, b_ldg_reg1.w, a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], C_frag[i * 4+3][0], C_frag[i * 4+3][1], C_frag[i * 4+3][2], C_frag[i * 4+3][3]);
				// 				}
				a_ldg_reg[0] += (b_ldg_reg0.x + b_ldg_reg1.x + C_frag[i * 4 + 3][0]);
				a_ldg_reg[1] += (b_ldg_reg0.y + b_ldg_reg1.y + C_frag[i * 4 + 3][1]);
				a_ldg_reg[2] += (b_ldg_reg0.z + b_ldg_reg1.z + C_frag[i * 4 + 3][2]);
				a_ldg_reg[3] += (b_ldg_reg0.w + b_ldg_reg1.w + C_frag[i * 4 + 3][3]);
				// 				if(a_ldg_reg[0]+a_ldg_reg[1]+a_ldg_reg[2]+a_ldg_reg[3]!=0){
				// 				    printf("3-version-%f, %f, %f, %f, th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
				// 				}
				if (blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32 < n && blockIdx.y * 32 + mma_tid_y * 4 + i * 16 + 3 < m) {
					stg128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], C + (blockIdx.y * 32 + mma_tid_y * 4 + i * 16 + 3)*n + blockIdx.x * 64 + mma_tid_x * 4 + (warp_id % 2) * 32);
				}
			}
		}
	}
	//	else {
	//#pragma unroll
	//		for (int i = 0; i < 2; ++i) {
	//#pragma unroll
	//			for (int j = 0; j < 2; ++j) {
	//				StgFrag stg_frag(C_frag, j, i);

	//				C_tile_wb(stg_frag,
	//					C_stg_ptr + i * 16 * n + j * 32,
	//					C_lds_ptr,
	//					C_sts_addr,
	//					m,
	//					n,
	//					m_idx + i * 16,
	//					n_idx + j * 32);
	//			}
	//		}
	//	}
}






//float* random_matrix(int row, int col) {
//	float* mat = new float[row * col];
//
//
//	for (int i = 0; i < row; ++i) {
//		for (int j = 0; j < col; ++j) {
//			if (i * col + j + 1 < 10) {
//				mat[i * col + j] = i * col + j + 1;
//			}
//			else {
//				mat[i * col + j] = 0.5;
//			}
//		}
//	}
//
//	return mat;
//}

float* random_matrix(int row, int col) {
	float* mat = new float[row * col];


	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			mat[i * col + j] = 0;
		}
	}

	return mat;
}


void print_mat(float* mat, int row, int col) {
	/*Display the matrix for visualizatoin*/
	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			cout << mat[i * col + j] << " ";
		}cout << endl;
	}
	cout << "\n" << endl;
}



int main()
{
	const int m = 3072, k = 3072, n = 64;
	float* a = random_matrix(m, k);
	float* b = random_matrix(k, n);
	float* c = new float[m*n];

	float* dev_a, *dev_b, *dev_c;

	cudaMalloc((void**)&dev_a, m * k * sizeof(float));
	cudaMalloc((void**)&dev_b, k * n * sizeof(float));
	cudaMalloc((void**)&dev_c, m * n * sizeof(float));

	cudaMemcpy(dev_a, a, m * k * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, b, k * n * sizeof(float), cudaMemcpyHostToDevice);


	constexpr int BLOCK = 64;
	dim3 grid((n + BLOCK - 1) / BLOCK, (m + 32 - 1) / 32);
	int repeat = 1;


	cudaEvent_t start, stop;
	cudaEventCreate(&start);
	cudaEventCreate(&stop);
	cudaEventRecord(start);
	cudaEventQuery(start);

	for (int i = 0; i < repeat; i++) {
		sgemm_128x128x8 << <grid, 256 >> > (m, n, k, dev_a, dev_b, dev_c);
	}


	cudaEventRecord(stop);
	cudaEventSynchronize(stop);
	float elapsed_time;
	cudaEventElapsedTime(&elapsed_time, start, stop);
	printf("Time = %g ms .\n", elapsed_time / repeat);
	cudaEventDestroy(start);
	cudaEventDestroy(stop);


	cudaMemcpy(c, dev_c, m * n * sizeof(float), cudaMemcpyDeviceToHost);

	//cout << 'a' << endl;
	//print_mat(a, m, k);
	//cout << 'b' << endl;
	//print_mat(b, k, n);
	//cout << 'c' << endl;
	//print_mat(c, m, n);
}
