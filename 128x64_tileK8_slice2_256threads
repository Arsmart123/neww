#include<iostream>
using namespace std;
#include <cstdint>
#include <cstdlib>
#include <cstdio>
#include <cmath>
#include <vector>

#define FETCH_FLOAT4(pointer) (reinterpret_cast<float4*>(&(pointer))[0])

__device__ __forceinline__ void stg128(const float &reg0, const float &reg1,
	const float &reg2, const float &reg3,
	const float *addr) {
	asm volatile("st.global.v4.f32 [%0], {%1, %2, %3, %4};\n"
		:
	: "l"(addr), "f"(reg0), "f"(reg1), "f"(reg2), "f"(reg3));
}

void random_init(float *data, size_t size) {
	for (size_t i = 0; i < size; ++i) {
		data[i] = float(rand()) / RAND_MAX;
	}
}

bool check(const float *A,
	const float *B,
	const float *C,
	int m, int n, int k) {
	for (int i = 0; i < m; ++i) {
		for (int j = 0; j < n; ++j) {
			float sum = 0.f;
			for (int p = 0; p < k; ++p) {
				sum += A[i * k + p] * B[j + p * n];
			}

			if (std::fabs(sum - C[i * n + j]) / std::fabs(sum) > 1e-5f) {
				printf("C[%d][%d] not match, %f vs %f\n", i, j, sum, C[i * n + j]);
				return false;
			}
		}
	}

	return true;
}

__device__ __forceinline__
uint32_t smem_u32addr(const void *smem_ptr) {
	uint32_t addr;
	asm("{.reg .u64 u64addr;\n"
		" cvta.to.shared.u64 u64addr, %1;\n"
		" cvt.u32.u64 %0, u64addr;}\n"
		: "=r"(addr)
		: "l"(smem_ptr)
	);

	return addr;
}

__device__ __forceinline__
void ldg32_nc(float &reg, const void *ptr, bool guard) {
	asm volatile (
		"{.reg .pred p;\n"
		" setp.ne.b32 p, %2, 0;\n"
#if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 && \
    __CUDA_ARCH__ >= 750
		" @p ld.global.nc.L2::128B.f32 %0, [%1];}\n"
#else
		" @p ld.global.nc.f32 %0, [%1];}\n"
#endif
		: "=f"(reg)
		: "l"(ptr), "r"((int)guard)
		);
}

__device__ __forceinline__ void ldg32_nc_0(float &reg, const void *ptr) {
	asm volatile("{mov.b32 %0, 0;\n"
#if __CUDACC_VER_MAJOR__ >= 11 && __CUDACC_VER_MINOR__ >= 4 &&                 \
    __CUDA_ARCH__ >= 750
		"ld.global.nc.L2::128B.f32 %0, [%1];}\n"
#else
		"ld.global.nc.f32 %0, [%1];}\n"
#endif
		: "=f"(reg)
		: "l"(ptr));
}

__device__ __forceinline__
void stg32(const float &reg, void *ptr, bool guard) {
	asm volatile (
		"{.reg .pred p;\n"
		" setp.ne.b32 p, %2, 0;\n"
		" @p st.global.f32 [%0], %1;}\n"
		: : "l"(ptr), "f"(reg), "r"((int)guard)
		);
}

__device__ __forceinline__
void lds128(float &reg0, float &reg1,
	float &reg2, float &reg3,
	const uint32_t &addr) {
	asm volatile (
		"ld.shared.v4.f32 {%0, %1, %2, %3}, [%4];\n"
		: "=f"(reg0), "=f"(reg1), "=f"(reg2), "=f"(reg3)
		: "r"(addr)
		);
}

__device__ __forceinline__
void sts32(const float &reg, const uint32_t &addr) {
	asm volatile (
		"st.shared.f32 [%0], %1;\n"
		: : "r"(addr), "f"(reg)
		);
}

__device__ __forceinline__
void sts128(const float &reg0, const float &reg1,
	const float &reg2, const float &reg3,
	const uint32_t &addr) {
	asm volatile (
		"st.shared.v4.f32 [%0], {%1, %2, %3, %4};\n"
		: : "r"(addr), "f"(reg0), "f"(reg1), "f"(reg2), "f"(reg3)
		);
}

struct StgFrag {
	float data[4][4];

	__device__ __forceinline__
		StgFrag(const float(&C_frag)[8][8], int tile_x, int tile_y) {
#pragma unroll
		for (int i = 0; i < 4; ++i) {
#pragma unroll
			for (int j = 0; j < 4; ++j) {
				data[i][j] = C_frag[tile_y * 4 + i][tile_x * 4 + j];
			}
		}
	}
};

__device__ __noinline__
void C_tile_wb(StgFrag C_frag,
	float *C_stg_ptr,
	const float *C_lds_ptr,
	uint32_t C_sts_addr,
	uint32_t m,
	uint32_t n,
	uint32_t m_idx,
	uint32_t n_idx) {
	__syncthreads();

#pragma unroll
	for (int i = 0; i < 4; ++i) {
		sts128(C_frag.data[i][0],
			C_frag.data[i][1],
			C_frag.data[i][2],
			C_frag.data[i][3],
			C_sts_addr + i * 8 * sizeof(float4));
	}

	__syncthreads();

	uint32_t m_guard = m < m_idx ? 0 : m - m_idx;

#pragma unroll
	for (int i = 0; i < 16; ++i) {
		stg32(C_lds_ptr[i * 32],
			C_stg_ptr + i * n,
			i < m_guard && n_idx < n);
	}
}

/*
 * matrix A, B and C: row-major
 *
 * mma block:
 * thread block tile: m128n128k8
 * warp tile: m32n64k8
 * thread tile: m8n8k8
 * thread fragment:
 *     matrixA: 8x1 FP32
 *     matrixB: 1x8 FP32
 *
 * ----------------------------------------------------------------
 * thread block tile map:
 *
 *                                128
 *                    --|---------------------|
 *             B_tile  8|                     |
 *                    --|---------------------|
 *
 *  A_tile   | 8 |      |    64    |
 *         --|---|    --|----------|----------|
 *           |   |    32|  warp_0  |  warp_1  |
 *           |   |    --|----------|----------|
 *           |   |      |  warp_2  |  warp_3  |
 *        128|   |      |----------|----------|
 *           |   |      |  warp_4  |  warp_5  |
 *           |   |      |----------|----------|
 *           |   |      |  warp_6  |  warp_7  |
 *         --|---|      |----------|----------|
 *
 * ----------------------------------------------------------------
 * warp tile map:
 *
 * 'z' thread map to avoid LDS.128 shared memory broadcast limitation.
 *
 *              |              32               ||
 *     B_frag --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
 *             1|///|   |   |   |   |   |   |   ||///|   |   |   |   |   |   |   |
 *            --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|
 * A_frag       | 4 |                           ||
 *    | 1 |                                     ||
 *  --|---|--   |---|---|---|---|---|---|---|---||---|---------------------------|
 *    |///|4    |t0 |t2 |t4 |t6 |t8 |t10|t12|t14||t0 |                           |
 *    |---|--   |---|---|---|---|---|---|---|---||---|                           |
 *    |   |     |t1 |t3 |t5 |t7 |t9 |t11|t13|t15||                               |
 *  16|---|     |---|---|---|---|---|---|---|---||                               |
 *    |   |     |t16|t18|t20|t22|t24|t26|t28|t30||                               |
 *    |---|     |---|---|---|---|---|---|---|---||                               |
 *    |   |     |t17|t19|t21|t23|t25|t27|t29|t31||                               |
 *  ==|===|=====|===|===|===|===|===|===|===|===||===|============================
 *    |///|     |t0 |                           ||t0 |                           |
 *    |---|     |---|                           ||---|                           |
 *    |   |     |                               ||                               |
 *    |---|     |                               ||                               |
 *    |   |     |                               ||                               |
 *    |---|     |                               ||                               |
 *    |   |     |                               ||                               |
 *    |---|     |-------------------------------||-------------------------------|
 *
 */
__global__ void __launch_bounds__(256, 2) sgemm_128x128x8(uint32_t m,
	uint32_t n,
	uint32_t k,
	float *A,
	float *B,
	float *C) {
	/*
	 * matrix A & B thread block tile shared memory (double buffer)
	 * matrix A: 132 * 8 * 4Byte/item * double buffer = 4.125KB * 2
	 * matrix B: 128 * 8 * 4Byte/item * double buffer = 8KB
	 *
	 * for double buffer faster switch, A_smem requires 8KB * 2 shared memory
	 * and 16KB aligned, B_smem should be 8KB aligned, then the double buffer
	 * can be switched by only 1 xor instruction:
	 *     (uint32_t &)A_smem ^= 0x2000;
	 *     (uint32_t &)B_smem ^= 0x1000;
	 */
	__shared__ __align__(8 * 1024) char smem[25088];  // 此处需要24.5KB
	float *A_smem = reinterpret_cast<float *>(smem);  // A占用16.5KB
	float *B_smem = reinterpret_cast<float *>(smem + 16896);

	// A, B and C register fragment
	float A_frag[2][8];
	float B_frag[2][8];
	float C_frag[8][8];
#pragma unroll
	for (int i = 0; i < 8; ++i) {
#pragma unroll
		for (int j = 0; j < 8; ++j) {
			C_frag[i][j] = 0;
		}
	}

	const uint32_t lane_id = threadIdx.x % 32;  // 我感觉应该不怎么改也行。。。之后要是通不过再检查这里吧。。。
	const uint32_t warp_id = threadIdx.x / 32;

	// 4x8 threads each warp for FFMA
	const uint32_t mma_tid_x = (lane_id / 2) % 8;
	const uint32_t mma_tid_y = (lane_id / 16) * 2 + (lane_id % 2);

	// A_tile & B_tile ldg pointer
	int from_a = (blockIdx.y * 128 + (threadIdx.x % 128) / 8 * 8) * k + (threadIdx.x % 128) % 8 + (threadIdx.x / 128)*(k / 2);
	int from_b = ((threadIdx.x % 128) / 16 + (threadIdx.x / 128)*(k / 2)) * n + blockIdx.x * 64 + (threadIdx.x % 128) % 16 * 4;

	// A_tile & B_tile sts/lds pointer
	// using uint32_t pointer for faster double buffer switch

	uint32_t A_lds_addr = smem_u32addr(
		A_smem + (warp_id % 4) * 32 + mma_tid_y * 4 + (threadIdx.x / 128) * 132 * 8);  // 这里只需要32，一轮循环里只有128个值，然后+132的工作是由lds128来执行的。
	uint32_t B_lds_addr = smem_u32addr(
		B_smem + mma_tid_x * 4 + (threadIdx.x / 128) * 64 * 8);  // 读取共享内存，存到寄存器去


	float4 b_ldg_reg;
	float a_ldg_reg[8];


	uint32_t a_sts_addr = smem_u32addr(A_smem + ((threadIdx.x % 128) % 8) * 132 + ((threadIdx.x % 128) / 8) * 8 + (threadIdx.x / 128) * 132 * 8);
	uint32_t b_sts_addr = smem_u32addr(B_smem + ((threadIdx.x % 128) / 16) * 64 + ((threadIdx.x % 128) % 16) * 4 + (threadIdx.x / 128) * 64 * 8);
	// 1'st A&B tile loaded before the k_tile loop
	uint32_t k_tiles = (k / 2 + 7) / 8 - 1;
	uint32_t first_k_tile = k / 2 - k_tiles * 8 + (k / 2)*(threadIdx.x / 128);

	// load 1'st tile to shared memory
	{
		// load first
		// load gmem to smem for ashare
// 		if(threadIdx.x==0&&blockIdx.x==0){
// 		    printf("first_k_tile=%d\n", first_k_tile);
// 		}
#pragma unroll
		for (int i = 0; i < 8; ++i) {
			if ((threadIdx.x % 128) % 8 + (threadIdx.x / 128)*(k / 2) < first_k_tile  && blockIdx.y * 128 + (threadIdx.x % 128) / 8 * 8 + i < m) {
				ldg32_nc_0(a_ldg_reg[i], (const char *)(A + from_a) + i * k * sizeof(float));
			}
			else {
				a_ldg_reg[i] = 0;
			}
		}
		// 		printf("%f %f %f %f th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
		sts128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], a_sts_addr);
		sts128(a_ldg_reg[4], a_ldg_reg[5], a_ldg_reg[6], a_ldg_reg[7], a_sts_addr + sizeof(float) * 4);
		// 检查此处这样加4可不可以。。。？

			  // load gmem to smem for bshare


		if (from_b < (1 + (threadIdx.x % 128) / 16 + (threadIdx.x / 128)*(k / 2))*n && (threadIdx.x % 128) / 16 + (threadIdx.x / 128)*(k / 2) < first_k_tile) {
			b_ldg_reg = FETCH_FLOAT4(B[from_b]);
		}
		else {
			b_ldg_reg = float4{ 0, 0, 0, 0 };
		}

		FETCH_FLOAT4(B_smem[((threadIdx.x % 128) / 16) * 64 + ((threadIdx.x % 128) % 16) * 4 + (threadIdx.x / 128) * 64 * 8]) = b_ldg_reg;
		__syncthreads();

		// add offset and flip flag
		from_a += k / 2 - k_tiles * 8;;
		from_b += (k / 2 - k_tiles * 8) * n;
		a_sts_addr += 132 * 8 * 2 * sizeof(float);  // 此处的*2是因为slice2！！！
		b_sts_addr += 64 * 8 * 2 * sizeof(float);
	}

	// 	if (threadIdx.x == 0 && blockIdx.x == 0) {
	// 		for (int ii = 0; ii < 16; ii++) {
	// 			for (int jj = 0; jj < 128; jj++) {
	// 				if (A_smem[ii * 132 + jj] != 0) {
	// 					printf("A_smem[%d][%d]=%f  ", ii, jj, A_smem[ii * 132 + jj]);
	// 				}
	// 			}
	// 			printf("\n");
	// 		}
	// 		printf("\n");
	//
	// 		for (int ii = 0; ii < 16; ii++) {
	// 			for (int jj = 0; jj < 64; jj++) {
	// 				if (B_smem[ii * 64 + jj] != 0) {
	// 					printf("B_smem[%d][%d]=%f  ", ii, jj, B_smem[ii * 64 + jj]);
	// 				}
	// 			}
	// 			printf("\n");
	// 		}
	// 		printf("\n");
	// 	}

		// load 1'st fragment
	lds128(A_frag[0][0], A_frag[0][1], A_frag[0][2], A_frag[0][3],
		A_lds_addr);
	lds128(A_frag[0][4], A_frag[0][5], A_frag[0][6], A_frag[0][7],
		A_lds_addr + 16 * sizeof(float));
	lds128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3],
		B_lds_addr);
	lds128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7],
		B_lds_addr + 32 * sizeof(float));

	// 	if(threadIdx.x==129){
	// 	    for(int ii=0;ii<8;ii++){
	// 	        printf("A_frag[%d]=%f  ", ii, A_frag[0][ii]);
	// 	    }
	// 	    printf("\n");
	// 	    for(int ii=0;ii<8;ii++){
	// 	        printf("B_frag[%d]=%f  ", ii, B_frag[0][ii]);
	// 	    }
	// 	    printf("\n");
	// 	}
	int jump = 0;
	// k_tiles loop
	for (; k_tiles > 0; --k_tiles) {
		jump ^= 1;
#pragma unroll
		for (int k_frag = 0; k_frag < 8; ++k_frag) {
			// store next A&B tile to shared memory
			if (k_frag == 7) {
				sts128(a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3],
					a_sts_addr);
				sts128(a_ldg_reg[4], a_ldg_reg[5], a_ldg_reg[6], a_ldg_reg[7],
					a_sts_addr + sizeof(float) * 4);

				sts128(b_ldg_reg.x, b_ldg_reg.y, b_ldg_reg.z, b_ldg_reg.w, b_sts_addr);

				__syncthreads();

				//                 if(threadIdx.x==0 && blockIdx.x==0){
				//                     for(int ii=0;ii<4;ii++){
				//                         for(int jj=0;jj<64;jj++){
				//                             if(A_smem[ii*68+jj+64*4*2*inddd]!=0){
				//                                 printf("11A_smem[%d][%d]=%f  ", ii, jj, A_smem[ii*68+jj+64*4*2*inddd]);
				//                             }
				//                         }
				//                         printf("\n");
				//                     }
				//                     printf("\n");
				//
				//
				//                     for(int ii=0;ii<8;ii++){
				//                         for(int jj=0;jj<64;jj++){
				//                             if(B_smem[ii*64+jj+64*8*2*jump]!=0){
				//                                 printf("11B_smem[%d][%d]=%f  ", ii, jj, B_smem[ii*64+jj+64*8*2*jump]);
				//                             }
				//                         }
				//                         printf("\n");
				//                     }
				//                     printf("\n");
				//                 }
												// switch double buffer

				if (jump == 1) {
					A_lds_addr += 132 * 8 * 2 * sizeof(float); // slice2,此处需要*2！！！
					B_lds_addr += 64 * 8 * 2 * sizeof(float);
					a_sts_addr -= 132 * 8 * 2 * sizeof(float);
					b_sts_addr -= 64 * 8 * 2 * sizeof(float);
				}
				else {
					A_lds_addr -= 132 * 8 * 2 * sizeof(float);
					B_lds_addr -= 64 * 8 * 2 * sizeof(float);
					a_sts_addr += 132 * 8 * 2 * sizeof(float);
					b_sts_addr += 64 * 8 * 2 * sizeof(float);
				}
				//if (threadIdx.x == 0) {
				//	printf("A_lds_addr=%u, new_A=%u\n", A_lds_addr, A_lds_addr + 132 * 8 * 4);
				//}
				// ldg pointer for next tile
				from_a += 8;  // 上面的from_a += 需要特殊写法，因为只向前first_k步，此处倒是不需要
				from_b += 8 * n;
			}

			// load next A&B fragment from shared memory to register
			lds128(A_frag[(k_frag + 1) % 2][0],
				A_frag[(k_frag + 1) % 2][1],
				A_frag[(k_frag + 1) % 2][2],
				A_frag[(k_frag + 1) % 2][3],
				A_lds_addr + (k_frag + 1) % 8 * 132 * sizeof(float));
			lds128(A_frag[(k_frag + 1) % 2][4],
				A_frag[(k_frag + 1) % 2][5],
				A_frag[(k_frag + 1) % 2][6],
				A_frag[(k_frag + 1) % 2][7],
				A_lds_addr + ((k_frag + 1) % 8 * 132 + 16) * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][0],
				B_frag[(k_frag + 1) % 2][1],
				B_frag[(k_frag + 1) % 2][2],
				B_frag[(k_frag + 1) % 2][3],
				B_lds_addr + (k_frag + 1) % 8 * 64 * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][4],
				B_frag[(k_frag + 1) % 2][5],
				B_frag[(k_frag + 1) % 2][6],
				B_frag[(k_frag + 1) % 2][7],
				B_lds_addr + ((k_frag + 1) % 8 * 64 + 32) * sizeof(float));

			// load next A&B tile
			if (k_frag == 0) {
				if (from_b < (1 + (threadIdx.x % 128) / 16)*n + (-k_tiles * 8 + k / 2 + (threadIdx.x / 128)*(k / 2))*n && (-k_tiles * 8 + k / 2) + (threadIdx.x % 128) / 16 + (threadIdx.x / 128)*(k / 2) < k) {
					b_ldg_reg = FETCH_FLOAT4(B[from_b]);
				}
				else {
					b_ldg_reg = float4{ 0, 0, 0, 0 };
				}
				//                 if(threadIdx.x==0 || threadIdx.x==16 || threadIdx.x==32 || threadIdx.x==48){
				//                     printf("mm%f %f %f %f th=%d, aa=%d<aaa=%d, bb=%d<bbb=%d, k_tiles=%d, (-k_tiles*4+k)=%d\n", b_ldg_reg.x, b_ldg_reg.y, b_ldg_reg.z, b_ldg_reg.w, threadIdx.x, from_b, (1+threadIdx.x/16)*n + (-k_tiles*4+k)*n, (-k_tiles*4+k)+threadIdx.x/16, k, k_tiles, (-k_tiles*4+k));
				//                 }


#pragma unroll
				for (int i = 0; i < 8; ++i) {
					if ((threadIdx.x % 128) % 8 + (-k_tiles * 8 + k / 2) < k && blockIdx.y * 128 + (threadIdx.x % 128) / 8 * 8 + i < m) {
						ldg32_nc_0(a_ldg_reg[i], (const char *)(A + from_a) + i * k * sizeof(float));
					}
					else {
						a_ldg_reg[i] = 0;
					}
					//                     printf("mmm%f %f %f %f th=%d\n", a_ldg_reg[0], a_ldg_reg[1], a_ldg_reg[2], a_ldg_reg[3], threadIdx.x);
				}
			}

			// FFMA loop
#pragma unroll
			for (int i = 0; i < 8; ++i) {
#pragma unroll
				for (int j = 0; j < 8; ++j) {
					C_frag[i][j] += A_frag[k_frag % 2][i] *
						B_frag[k_frag % 2][j];
					// 					if (threadIdx.x == 129 && blockIdx.x == 0) {
					// 						printf("00C_frag[%d][%d]=%f  <=  A_frag[%d][%d]=%f  *  B_frag[%d][%d]=%f\n", i, j, C_frag[i][j], k_frag % 2, i, A_frag[k_frag % 2][i], k_frag % 2, j, B_frag[k_frag % 2][j]);
					// 					}
				}
			}
		}
	}
	// 这样最后一个循环就不需要再预读取了。确实。最后一轮预取是没有必要的
	// FFMA for the last tile
#pragma unroll
	for (int k_frag = 0; k_frag < 8; ++k_frag) {
		if (k_frag < 7) {
			// load next A&B fragment from shared memory to register
			lds128(A_frag[(k_frag + 1) % 2][0],
				A_frag[(k_frag + 1) % 2][1],
				A_frag[(k_frag + 1) % 2][2],
				A_frag[(k_frag + 1) % 2][3],
				A_lds_addr + (k_frag + 1) % 8 * 132 * sizeof(float));
			lds128(A_frag[(k_frag + 1) % 2][4],
				A_frag[(k_frag + 1) % 2][5],
				A_frag[(k_frag + 1) % 2][6],
				A_frag[(k_frag + 1) % 2][7],
				A_lds_addr + ((k_frag + 1) % 8 * 132 + 16) * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][0],
				B_frag[(k_frag + 1) % 2][1],
				B_frag[(k_frag + 1) % 2][2],
				B_frag[(k_frag + 1) % 2][3],
				B_lds_addr + (k_frag + 1) % 8 * 64 * sizeof(float));
			lds128(B_frag[(k_frag + 1) % 2][4],
				B_frag[(k_frag + 1) % 2][5],
				B_frag[(k_frag + 1) % 2][6],
				B_frag[(k_frag + 1) % 2][7],
				B_lds_addr + ((k_frag + 1) % 8 * 64 + 32) * sizeof(float));
		}


		//         if(threadIdx.x==129){
		//             for(int ii=0;ii<8;ii++){
		//                 printf("11A_frag[%d][%d]=%f  ",(k_frag + 1) % 2, ii, A_frag[(k_frag + 1) % 2][ii]);
		//             }
		//             printf("\n");
		//             for(int ii=0;ii<8;ii++){
		//                 printf("11B_frag[%d][%d]=%f  ",(k_frag + 1) % 2, ii, B_frag[(k_frag + 1) % 2][ii]);
		//             }
		//             printf("\n");
		//         }

				// FFMA loop
#pragma unroll
		for (int i = 0; i < 8; ++i) {
#pragma unroll
			for (int j = 0; j < 8; ++j) {
				C_frag[i][j] += A_frag[k_frag % 2][i] *
					B_frag[k_frag % 2][j];
				// 				if (threadIdx.x == 129 && blockIdx.x == 0) {
				// 					printf("11C_frag[%d][%d]=%f  <=  A_frag[%d][%d]=%f  *  B_frag[%d][%d]=%f\n", i, j, C_frag[i][j], k_frag % 2, i, A_frag[k_frag % 2][i], k_frag % 2, j, B_frag[k_frag % 2][j]);
				// 				}
			}
		}
	}
	//     if(threadIdx.x==64){
	//         for(int ii=0;ii<8;ii++){
	//             for(int jj=0;jj<8;jj++){
	//                 if(C_frag[ii][jj]!=0){
	//                     printf("%d,%d final_C_frag[%d][%d]=%f\n",threadIdx.x, threadIdx.y, ii, jj, C_frag[ii][jj]);
	//                 }
	//             }
	//         }
	//     }
		//
		//
		//
		//
			// C_tile write back, reuse A&B tile shared memory buffer
	uint32_t C_sts_addr = smem_u32addr((float4 *)(smem + warp_id * 2048) +
		mma_tid_y * 4 * 8 + mma_tid_x); // 比如，th=1的mma_tid_y * 4 * 8 + mma_tid_x是32，则要乘4（不需要真的写*4，而是float4帮我们自动*4），因为一个th有4行;   再乘4（这由smem_u32addr执行），因为float占4
	uint32_t C_lds_ptr = smem_u32addr(A_smem + (mma_tid_y * 4 * 8 + mma_tid_x) * 4 + (warp_id % 2) * 16 * 32);// 为什么没法利用每个thread已经有的reg值？有可能！！每个thread再分配出12个值，原本的不动。然后最后加到新的reg里即可！有时间可以再想想这个！关键是，这个thread被分配来干什么，已经拥有了什么，所以就不需要取这个值。（不过不知道能提速多少）
	uint32_t C_lds_addr = smem_u32addr(A_smem + threadIdx.x / 8 * 32 + (threadIdx.x % 8) * 4);
	//     if(threadIdx.x==64){
	//         printf("loc=%d, pre=%d, lat=%d\n", C_lds_ptr, (mma_tid_y * 4 * 8 + mma_tid_x)*4, (threadIdx.x/32)*16*32);
	//     }
		//const uint32_t C_loc = warp_id / 2;


	uint32_t m_idx = blockIdx.y * 128;
	//uint32_t n_idx = blockIdx.x * 64 + lane_id + (warp_id % 2) * 64;  // 这两个参数指定了当前block的起始写入C的位置。


//  	float *C_stg_ptr = C + m_idx * n + n_idx;

	if (m_idx >= m) {
		return;
	}
	else if (m_idx + 32 <= m) {
		//  		uint32_t n_guard = n < n_idx ? 0 : n - n_idx;

#pragma unroll
		for (int i = 0; i < 2; ++i) {


			for (int j = 0; j < 2; ++j) {
				__syncthreads();

#pragma unroll
				for (int p = 0; p < 4; ++p) {
					sts128(C_frag[i * 4 + p][j * 4],
						C_frag[i * 4 + p][j * 4 + 1],
						C_frag[i * 4 + p][j * 4 + 2],
						C_frag[i * 4 + p][j * 4 + 3],
						C_sts_addr + p * 8 * sizeof(float4));
				}

				__syncthreads();

				//                 if(threadIdx.x==0){
				//                     int line_zero = 0;
				//                     for(int ii=16*2;ii<16*3;ii++){
				//                         line_zero = 0;
				//                         for(int jj=0;jj<32;jj++){
				//                             if(A_smem[ii*32+jj]!=0){
				//                                 line_zero = 1;
				//                                 printf("C_smem[%d][%d]=%f  ", ii, jj, A_smem[ii*32+jj]);
				//                             }
				//                         }
				//                         if(line_zero == 1){
				//                             printf("\n");
				//                         }
				//                     }
				//                     printf("\n");
				//                 }

				lds128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], C_lds_addr);
				lds128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7], C_lds_addr + 32 * 32 * sizeof(float));
				lds128(B_frag[1][0], B_frag[1][1], B_frag[1][2], B_frag[1][3],
					C_lds_addr + (32 * 64) * sizeof(float));
				lds128(B_frag[1][4], B_frag[1][5], B_frag[1][6], B_frag[1][7],
					C_lds_addr + (32 * 64) * sizeof(float) + 32 * 32 * sizeof(float));

				// 				if(threadIdx.x==0){
				// 				    printf("to_add %f %f %f %f, %f %f %f %f,%f %f %f %f,%f %f %f %f\n", B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7], B_frag[1][0], B_frag[1][1], B_frag[1][2], B_frag[1][3], B_frag[1][4], B_frag[1][5], B_frag[1][6], B_frag[1][7]);
				// 				}

				B_frag[0][0] += B_frag[1][0];
				B_frag[0][1] += B_frag[1][1];
				B_frag[0][2] += B_frag[1][2];
				B_frag[0][3] += B_frag[1][3];

				B_frag[0][4] += B_frag[1][4];
				B_frag[0][5] += B_frag[1][5];
				B_frag[0][6] += B_frag[1][6];
				B_frag[0][7] += B_frag[1][7];

				// 				if(threadIdx.x==0){
				// 				    printf("final_add %f %f %f %f, %f %f %f %f\n", B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7]);
				// 				}

				if (blockIdx.x * 64 + (threadIdx.x % 8) * 4 + j * 32 < n) {
					if (blockIdx.y * 128 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32 < m) {
						stg128(B_frag[0][0], B_frag[0][1], B_frag[0][2], B_frag[0][3], C + (blockIdx.y * 128 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32)*n + blockIdx.x * 64 + (threadIdx.x % 8) * 4 + j * 32);  // 先存前32*32部分。
					}
					if (blockIdx.y * 128 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32 + 64 < m) {
						stg128(B_frag[0][4], B_frag[0][5], B_frag[0][6], B_frag[0][7], C + (blockIdx.y * 128 + (threadIdx.x % 128) / 8 + i * 16 + (threadIdx.x / 128) * 32 + 64)*n + blockIdx.x * 64 + (threadIdx.x % 8) * 4 + j * 32);  // 先存前32*32部分。
					} // 此处一开始写成else if，和上面的形成二选一格局。
				}
			}
		}
	}
	//	else {
	//#pragma unroll
	//		for (int i = 0; i < 2; ++i) {
	//#pragma unroll
	//			for (int j = 0; j < 2; ++j) {
	//				StgFrag stg_frag(C_frag, j, i);

	//				C_tile_wb(stg_frag,
	//					C_stg_ptr + i * 16 * n + j * 32,
	//					C_lds_ptr,
	//					C_sts_addr,
	//					m,
	//					n,
	//					m_idx + i * 16,
	//					n_idx + j * 32);
	//			}
	//		}
	//	}
}



float* random_matrix(int row, int col) {
	float* mat = new float[row * col];


	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			if (i * col + j + 1 < 10) {
				mat[i * col + j] = i * col + j + 1;
			}
			else {
				mat[i * col + j] = 10;
			}
		}
	}

	return mat;
}


void print_mat(float* mat, int row, int col) {
	/*Display the matrix for visualizatoin*/
	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			cout << mat[i * col + j] << " ";
		}cout << endl;
	}
	cout << "\n" << endl;
}


float* random_matrix_1(int row, int col) {
	float* mat = new float[row * col];


	for (int i = 0; i < row; ++i) {
		for (int j = 0; j < col; ++j) {
			mat[i * col + j] = 1;
		}
	}

	return mat;
}



int main()
{
	const int m = 3072, k = 3072, n = 64;
	float* a = random_matrix(k, m);
	float* b = random_matrix(k, n);
	float* c = new float[m * n];

	float* dev_a, *dev_b, *dev_c;

	cudaMalloc((void**)&dev_a, m * k * sizeof(float));
	cudaMalloc((void**)&dev_b, k * n * sizeof(float));
	cudaMalloc((void**)&dev_c, m * n * sizeof(float));

	cudaMemcpy(dev_a, a, m * k * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, b, k * n * sizeof(float), cudaMemcpyHostToDevice);


	constexpr int BLOCK = 128;
	dim3 grid((n + 64 - 1) / 64, (m + BLOCK - 1) / BLOCK);
	int repeat = 1;






	cudaEvent_t start, stop;
	cudaEventCreate(&start);
	cudaEventCreate(&stop);
	cudaEventRecord(start);
	cudaEventQuery(start);

	for (int i = 0; i < repeat; i++) {
		sgemm_128x128x8 << <grid, 256 >> > (m, n, k, dev_a, dev_b, dev_c);
	}





	cudaEventRecord(stop);
	cudaEventSynchronize(stop);
	float elapsed_time;
	cudaEventElapsedTime(&elapsed_time, start, stop);
	printf("Time = %g ms .\n", elapsed_time / repeat);
	cudaEventDestroy(start);
	cudaEventDestroy(stop);


	cudaMemcpy(c, dev_c, m*n * sizeof(float), cudaMemcpyDeviceToHost);
	//bool chk = check(a, b, c, m, n, k);
	//printf("Matrix_C check: %s\n", chk ? "OK" : "Failed");
	//cout << 'a' << endl;
	//print_mat(a, k, m);
	//cout << 'b' << endl;
	//print_mat(b, k, n);
	//cout << 'c' << endl;
	//print_mat(c, m, n);
}
